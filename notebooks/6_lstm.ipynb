{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8tQJd2YSCfWR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7tqLMoKF6uq"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 6\n",
    "------------\n",
    "\n",
    "After training a skip-gram model in `5_word2vec.ipynb`, the goal of this notebook is to train a LSTM character model over [Text8](http://mattmahoney.net/dc/textdata) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MvEblsgEXxrd"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5993,
     "status": "ok",
     "timestamp": 1445965582896,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "RJ-o3UBUFtCw",
    "outputId": "d530534e-0791-4a94-ca6d-1c8f1b908a9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10838016\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to verify text8.zip. Can you get to it with a browser?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9f9c694d2879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text8.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31344016\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-9f9c694d2879>\u001b[0m in \u001b[0;36mmaybe_download\u001b[0;34m(filename, expected_bytes)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Failed to verify '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Can you get to it with a browser?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Failed to verify text8.zip. Can you get to it with a browser?"
     ]
    }
   ],
   "source": [
    "url = 'http://mattmahoney.net/dc/'\n",
    "\n",
    "def maybe_download(filename, expected_bytes):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        filename, _ = urlretrieve(url + filename, filename)\n",
    "    statinfo = os.stat(filename)\n",
    "    if statinfo.st_size == expected_bytes:\n",
    "        print('Found and verified %s' % filename)\n",
    "    else:\n",
    "        print(statinfo.st_size)\n",
    "        raise Exception('Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "    return filename\n",
    "\n",
    "filename = maybe_download('text8.zip', 31344016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5982,
     "status": "ok",
     "timestamp": 1445965582916,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "Mvf09fjugFU_",
    "outputId": "8f75db58-3862-404b-a0c3-799380597390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 100000000\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename):\n",
    "    with zipfile.ZipFile(filename) as f:\n",
    "        name = f.namelist()[0]\n",
    "        data = tf.compat.as_str(f.read(name))\n",
    "    return data\n",
    "  \n",
    "filename = \"../datasets/text8.zip\"\n",
    "text = read_data(filename)\n",
    "print('Data size %d' % len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ga2CYACE-ghb"
   },
   "source": [
    "Create a small validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6184,
     "status": "ok",
     "timestamp": 1445965583138,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "w-oBpfFG-j43",
    "outputId": "bdb96002-d021-4379-f6de-a977924f0d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99999000 ons anarchists advocate social relations based upon voluntary as\n",
      "1000  anarchism originated as a term of abuse first used against earl\n"
     ]
    }
   ],
   "source": [
    "valid_size = 1000\n",
    "valid_text = text[:valid_size]\n",
    "train_text = text[valid_size:]\n",
    "train_size = len(train_text)\n",
    "print(train_size, train_text[:64])\n",
    "print(valid_size, valid_text[:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zdw6i4F8glpp"
   },
   "source": [
    "Utility functions to map characters to vocabulary IDs and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6276,
     "status": "ok",
     "timestamp": 1445965583249,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "gAL1EECXeZsD",
    "outputId": "88fc9032-feb9-45ff-a9a0-a26759cc1f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected character: ï\n",
      "1 26 0 0\n",
      "a z  \n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(string.ascii_lowercase) + 1 # [a-z] + ' '\n",
    "first_letter = ord(string.ascii_lowercase[0])\n",
    "\n",
    "def char2id(char):\n",
    "    if char in string.ascii_lowercase:\n",
    "        return ord(char) - first_letter + 1\n",
    "    elif char == ' ':\n",
    "        return 0\n",
    "    else:\n",
    "        print('Unexpected character: %s' % char)\n",
    "        return 0\n",
    "\n",
    "def id2char(dictid):\n",
    "    if dictid > 0:\n",
    "        return chr(dictid + first_letter - 1)\n",
    "    else:\n",
    "        return ' '\n",
    "\n",
    "print(char2id('a'), char2id('z'), char2id(' '), char2id('ï'))\n",
    "print(id2char(1), id2char(26), id2char(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFwoyygOmWsL"
   },
   "source": [
    "Function to generate a training batch for the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6473,
     "status": "ok",
     "timestamp": 1445965583467,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "d9wMtjy5hCj9",
    "outputId": "3dd79c80-454a-4be0-8b71-4a4a357b3367"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ons anarchi', 'when milita', 'lleria arch', ' abbeys and', 'married urr', 'hel and ric', 'y and litur', 'ay opened f', 'tion from t', 'migration t', 'new york ot', 'he boeing s', 'e listed wi', 'eber has pr', 'o be made t', 'yer who rec', 'ore signifi', 'a fierce cr', ' two six ei', 'aristotle s', 'ity can be ', ' and intrac', 'tion of the', 'dy to pass ', 'f certain d', 'at it will ', 'e convince ', 'ent told hi', 'ampaign and', 'rver side s', 'ious texts ', 'o capitaliz', 'a duplicate', 'gh ann es d', 'ine january', 'ross zero t', 'cal theorie', 'ast instanc', ' dimensiona', 'most holy m', 't s support', 'u is still ', 'e oscillati', 'o eight sub', 'of italy la', 's the tower', 'klahoma pre', 'erprise lin', 'ws becomes ', 'et in a naz', 'the fabian ', 'etchy to re', ' sharman ne', 'ised empero', 'ting in pol', 'd neo latin', 'th risky ri', 'encyclopedi', 'fense the a', 'duating fro', 'treet grid ', 'ations more', 'appeal of d', 'si have mad']\n",
      "['ists advoca', 'ary governm', 'hes nationa', 'd monasteri', 'raca prince', 'chard baer ', 'rgical lang', 'for passeng', 'the nationa', 'took place ', 'ther well k', 'seven six s', 'ith a gloss', 'robably bee', 'to recogniz', 'ceived the ', 'icant than ', 'ritic of th', 'ight in sig', 's uncaused ', ' lost as in', 'cellular ic', 'e size of t', ' him a stic', 'drugs confu', ' take to co', ' the priest', 'im to name ', 'd barred at', 'standard fo', ' such as es', 'ze on the g', 'e of the or', 'd hiver one', 'y eight mar', 'the lead ch', 'es classica', 'ce the non ', 'al analysis', 'mormons bel', 't or at lea', ' disagreed ', 'ing system ', 'btypes base', 'anguages th', 'r commissio', 'ess one nin', 'nux suse li', ' the first ', 'zi concentr', ' society ne', 'elatively s', 'etworks sha', 'or hirohito', 'litical ini', 'n most of t', 'iskerdoo ri', 'ic overview', 'air compone', 'om acnm acc', ' centerline', 'e than any ', 'devotional ', 'de such dev']\n",
      "[' a']\n",
      "['an']\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_unrollings = 10\n",
    "\n",
    "class BatchGenerator(object):\n",
    "    def __init__(self, text, batch_size, num_unrollings):\n",
    "        self._text = text\n",
    "        self._text_size = len(text)\n",
    "        self._batch_size = batch_size\n",
    "        self._num_unrollings = num_unrollings\n",
    "        segment = self._text_size // batch_size\n",
    "        self._cursor = [ offset * segment for offset in range(batch_size)]\n",
    "        self._last_batch = self._next_batch()\n",
    "\n",
    "    def _next_batch(self):\n",
    "        \"\"\"Generate a single batch from the current cursor position in the data.\"\"\"\n",
    "        batch = np.zeros(shape=(self._batch_size, vocabulary_size), dtype=np.float)\n",
    "        for b in range(self._batch_size):\n",
    "            batch[b, char2id(self._text[self._cursor[b]])] = 1.0\n",
    "            self._cursor[b] = (self._cursor[b] + 1) % self._text_size\n",
    "        return batch\n",
    "  \n",
    "    def next(self):\n",
    "        \"\"\"Generate the next array of batches from the data. The array consists of\n",
    "        the last batch of the previous array, followed by num_unrollings new ones.\n",
    "        \"\"\"\n",
    "        batches = [self._last_batch]\n",
    "        for step in range(self._num_unrollings):\n",
    "            batches.append(self._next_batch())\n",
    "        self._last_batch = batches[-1]\n",
    "        return batches\n",
    "\n",
    "def characters(probabilities):\n",
    "    \"\"\"Turn a 1-hot encoding or a probability distribution over the possible\n",
    "    characters back into its (most likely) character representation.\"\"\"\n",
    "    return [id2char(c) for c in np.argmax(probabilities, 1)]\n",
    "\n",
    "def batches2string(batches):\n",
    "    \"\"\"Convert a sequence of batches back into their (most likely) string\n",
    "    representation.\"\"\"\n",
    "    s = [''] * batches[0].shape[0]\n",
    "    for b in batches:\n",
    "        s = [''.join(x) for x in zip(s, characters(b))]\n",
    "    return s\n",
    "\n",
    "train_batches = BatchGenerator(train_text, batch_size, num_unrollings)\n",
    "valid_batches = BatchGenerator(valid_text, 1, 1)\n",
    "\n",
    "print(batches2string(train_batches.next()))\n",
    "print(batches2string(train_batches.next()))\n",
    "print(batches2string(valid_batches.next()))\n",
    "print(batches2string(valid_batches.next()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KyVd8FxT5QBc"
   },
   "outputs": [],
   "source": [
    "def logprob(predictions, labels):\n",
    "    \"\"\"Log-probability of the true labels in a predicted batch.\"\"\"\n",
    "    predictions[predictions < 1e-10] = 1e-10\n",
    "    return np.sum(np.multiply(labels, -np.log(predictions))) / labels.shape[0]\n",
    "\n",
    "def sample_distribution(distribution):\n",
    "    \"\"\"Sample one element from a distribution assumed to be an array of normalized\n",
    "    probabilities.\n",
    "    \"\"\"\n",
    "    r = random.uniform(0, 1)\n",
    "    s = 0\n",
    "    for i in range(len(distribution)):\n",
    "        s += distribution[i]\n",
    "        if s >= r:\n",
    "            return i\n",
    "    return len(distribution) - 1\n",
    "\n",
    "def sample(prediction):\n",
    "    \"\"\"Turn a (column) prediction into 1-hot encoded samples.\"\"\"\n",
    "    p = np.zeros(shape=[1, vocabulary_size], dtype=np.float)\n",
    "    p[0, sample_distribution(prediction[0])] = 1.0\n",
    "    return p\n",
    "\n",
    "def random_distribution():\n",
    "    \"\"\"Generate a random column of probabilities.\"\"\"\n",
    "    b = np.random.uniform(0.0, 1.0, size=[1, vocabulary_size])\n",
    "    return b/np.sum(b, 1)[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8f67YXaDr4C"
   },
   "source": [
    "Simple LSTM Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Q5rxZK6RDuGe"
   },
   "outputs": [],
   "source": [
    "num_nodes = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  \n",
    "    # Parameters:\n",
    "    # Input gate: input, previous output, and bias.\n",
    "    ix = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "    im = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "    ib = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "    # Forget gate: input, previous output, and bias.\n",
    "    fx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "    fm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "    fb = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "    # Memory cell: input, state and bias.                             \n",
    "    cx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "    cm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "    cb = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "    # Output gate: input, previous output, and bias.\n",
    "    ox = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "    om = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "    ob = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "    # Variables saving state across unrollings.\n",
    "    saved_output = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "    saved_state = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "    # Classifier weights and biases.\n",
    "    w = tf.Variable(tf.truncated_normal([num_nodes, vocabulary_size], -0.1, 0.1))\n",
    "    b = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "    # Definition of the cell computation.\n",
    "    def lstm_cell(i, o, state):\n",
    "        \"\"\"Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n",
    "        Note that in this formulation, we omit the various connections between the\n",
    "        previous state and the gates.\"\"\"\n",
    "        input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n",
    "        forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n",
    "        update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n",
    "        state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "        output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n",
    "        return output_gate * tf.tanh(state), state\n",
    "\n",
    "    # Input data.\n",
    "    train_data = list()\n",
    "    for _ in range(num_unrollings + 1):\n",
    "        train_data.append(tf.placeholder(tf.float32, shape=[batch_size,vocabulary_size]))\n",
    "\n",
    "    train_inputs = train_data[:num_unrollings]\n",
    "    train_labels = train_data[1:]  # labels are inputs shifted by one time step.\n",
    "\n",
    "    # Unrolled LSTM loop.\n",
    "    outputs = list()\n",
    "    output = saved_output\n",
    "    state = saved_state\n",
    "    for i in train_inputs:\n",
    "        output, state = lstm_cell(i, output, state)\n",
    "        outputs.append(output)\n",
    "\n",
    "    # State saving across unrollings.\n",
    "    with tf.control_dependencies([saved_output.assign(output), saved_state.assign(state)]):\n",
    "    # Classifier.\n",
    "        logits = tf.nn.xw_plus_b(tf.concat(outputs, 0), w, b)\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=tf.concat(train_labels, 0), logits=logits))\n",
    "\n",
    "    # Optimizer.\n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(10.0, global_step, 5000, 0.1, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "    optimizer = optimizer.apply_gradients(zip(gradients, v), global_step=global_step)\n",
    "\n",
    "    # Predictions.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    # Sampling and validation eval: batch 1, no unrolling.\n",
    "    sample_input = tf.placeholder(tf.float32, shape=[1, vocabulary_size])\n",
    "    saved_sample_output = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "    saved_sample_state = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "    reset_sample_state = tf.group( \n",
    "        saved_sample_output.assign(tf.zeros([1, num_nodes])),\n",
    "        saved_sample_state.assign(tf.zeros([1, num_nodes])))\n",
    "    sample_output, sample_state = lstm_cell(sample_input, saved_sample_output, saved_sample_state)\n",
    "    with tf.control_dependencies([saved_sample_output.assign(sample_output),\n",
    "                                saved_sample_state.assign(sample_state)]):\n",
    "        sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 41
      },
      {
       "item_id": 80
      },
      {
       "item_id": 126
      },
      {
       "item_id": 144
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 199909,
     "status": "ok",
     "timestamp": 1445965877333,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "RD9zQCZTEaEm",
    "outputId": "5e868466-2532-4545-ce35-b403cf5d9de6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step 0: 3.293002 learning rate: 10.000000\n",
      "Minibatch perplexity: 26.92\n",
      "================================================================================\n",
      "i ztiuarbawgevpwwac qzouy ag xwi rhurln mf hsrr hyrqktxijyesrjrfcaepi mcyeye v  \n",
      "================================================================================\n",
      "Validation set perplexity: 20.07\n",
      "Average loss at step 1: 3.007713 learning rate: 10.000000\n",
      "Minibatch perplexity: 20.24\n",
      "================================================================================\n",
      "Validation set perplexity: 18.47\n",
      "Average loss at step 2: 2.907108 learning rate: 10.000000\n",
      "Minibatch perplexity: 18.30\n",
      "================================================================================\n",
      "Validation set perplexity: 17.81\n",
      "Average loss at step 3: 2.902946 learning rate: 10.000000\n",
      "Minibatch perplexity: 18.23\n",
      "================================================================================\n",
      "Validation set perplexity: 17.86\n",
      "Average loss at step 4: 2.913503 learning rate: 10.000000\n",
      "Minibatch perplexity: 18.42\n",
      "================================================================================\n",
      "Validation set perplexity: 19.29\n",
      "Average loss at step 5: 2.963594 learning rate: 10.000000\n",
      "Minibatch perplexity: 19.37\n",
      "================================================================================\n",
      "Validation set perplexity: 18.20\n",
      "Average loss at step 6: 2.913541 learning rate: 10.000000\n",
      "Minibatch perplexity: 18.42\n",
      "================================================================================\n",
      "Validation set perplexity: 18.30\n",
      "Average loss at step 7: 2.914312 learning rate: 10.000000\n",
      "Minibatch perplexity: 18.44\n",
      "================================================================================\n",
      "Validation set perplexity: 17.32\n",
      "Average loss at step 8: 2.855476 learning rate: 10.000000\n",
      "Minibatch perplexity: 17.38\n",
      "================================================================================\n",
      "Validation set perplexity: 17.26\n",
      "Average loss at step 9: 2.879287 learning rate: 10.000000\n",
      "Minibatch perplexity: 17.80\n",
      "================================================================================\n",
      "Validation set perplexity: 17.02\n",
      "Average loss at step 10: 2.854892 learning rate: 10.000000\n",
      "Minibatch perplexity: 17.37\n",
      "================================================================================\n",
      "Validation set perplexity: 16.88\n",
      "Average loss at step 11: 2.826971 learning rate: 10.000000\n",
      "Minibatch perplexity: 16.89\n",
      "================================================================================\n",
      "Validation set perplexity: 16.85\n",
      "Average loss at step 12: 2.843278 learning rate: 10.000000\n",
      "Minibatch perplexity: 17.17\n",
      "================================================================================\n",
      "Validation set perplexity: 17.34\n",
      "Average loss at step 13: 2.868423 learning rate: 10.000000\n",
      "Minibatch perplexity: 17.61\n",
      "================================================================================\n",
      "Validation set perplexity: 17.59\n",
      "Average loss at step 14: 2.767232 learning rate: 10.000000\n",
      "Minibatch perplexity: 15.91\n",
      "================================================================================\n",
      "Validation set perplexity: 17.57\n",
      "Average loss at step 15: 2.883163 learning rate: 10.000000\n",
      "Minibatch perplexity: 17.87\n",
      "================================================================================\n",
      "Validation set perplexity: 17.47\n",
      "Average loss at step 16: 2.857657 learning rate: 10.000000\n",
      "Minibatch perplexity: 17.42\n",
      "================================================================================\n",
      "Validation set perplexity: 17.19\n",
      "Average loss at step 17: 2.831409 learning rate: 10.000000\n",
      "Minibatch perplexity: 16.97\n",
      "================================================================================\n",
      "Validation set perplexity: 16.19\n",
      "Average loss at step 18: 2.758406 learning rate: 10.000000\n",
      "Minibatch perplexity: 15.77\n",
      "================================================================================\n",
      "Validation set perplexity: 15.74\n",
      "Average loss at step 19: 2.754686 learning rate: 10.000000\n",
      "Minibatch perplexity: 15.72\n",
      "================================================================================\n",
      "Validation set perplexity: 15.49\n",
      "Average loss at step 20: 2.764082 learning rate: 10.000000\n",
      "Minibatch perplexity: 15.86\n",
      "================================================================================\n",
      "Validation set perplexity: 15.32\n",
      "Average loss at step 21: 2.775618 learning rate: 10.000000\n",
      "Minibatch perplexity: 16.05\n",
      "================================================================================\n",
      "Validation set perplexity: 15.31\n",
      "Average loss at step 22: 2.733201 learning rate: 10.000000\n",
      "Minibatch perplexity: 15.38\n",
      "================================================================================\n",
      "Validation set perplexity: 15.47\n",
      "Average loss at step 23: 2.801213 learning rate: 10.000000\n",
      "Minibatch perplexity: 16.46\n",
      "================================================================================\n",
      "Validation set perplexity: 17.60\n",
      "Average loss at step 24: 2.895835 learning rate: 10.000000\n",
      "Minibatch perplexity: 18.10\n",
      "================================================================================\n",
      "Validation set perplexity: 21.63\n",
      "Average loss at step 25: 3.104173 learning rate: 10.000000\n",
      "Minibatch perplexity: 22.29\n",
      "================================================================================\n",
      "Validation set perplexity: 15.75\n",
      "Average loss at step 26: 2.800674 learning rate: 10.000000\n",
      "Minibatch perplexity: 16.46\n",
      "================================================================================\n",
      "Validation set perplexity: 15.94\n",
      "Average loss at step 27: 2.758464 learning rate: 10.000000\n",
      "Minibatch perplexity: 15.78\n",
      "================================================================================\n",
      "Validation set perplexity: 16.69\n",
      "Average loss at step 28: 2.857280 learning rate: 10.000000\n",
      "Minibatch perplexity: 17.41\n",
      "================================================================================\n",
      "Validation set perplexity: 14.61\n",
      "Average loss at step 29: 2.699949 learning rate: 10.000000\n",
      "Minibatch perplexity: 14.88\n",
      "================================================================================\n",
      "Validation set perplexity: 14.32\n",
      "Average loss at step 30: 2.692222 learning rate: 10.000000\n",
      "Minibatch perplexity: 14.76\n",
      "================================================================================\n",
      "Validation set perplexity: 14.25\n",
      "Average loss at step 31: 2.614055 learning rate: 10.000000\n",
      "Minibatch perplexity: 13.65\n",
      "================================================================================\n",
      "Validation set perplexity: 13.65\n",
      "Average loss at step 32: 2.693441 learning rate: 10.000000\n",
      "Minibatch perplexity: 14.78\n",
      "================================================================================\n",
      "Validation set perplexity: 13.62\n",
      "Average loss at step 33: 2.634211 learning rate: 10.000000\n",
      "Minibatch perplexity: 13.93\n",
      "================================================================================\n",
      "Validation set perplexity: 13.69\n",
      "Average loss at step 34: 2.607536 learning rate: 10.000000\n",
      "Minibatch perplexity: 13.57\n",
      "================================================================================\n",
      "Validation set perplexity: 13.28\n",
      "Average loss at step 35: 2.652040 learning rate: 10.000000\n",
      "Minibatch perplexity: 14.18\n",
      "================================================================================\n",
      "Validation set perplexity: 13.34\n",
      "Average loss at step 36: 2.567078 learning rate: 10.000000\n",
      "Minibatch perplexity: 13.03\n",
      "================================================================================\n",
      "Validation set perplexity: 14.27\n",
      "Average loss at step 37: 2.584822 learning rate: 10.000000\n",
      "Minibatch perplexity: 13.26\n",
      "================================================================================\n",
      "Validation set perplexity: 13.63\n",
      "Average loss at step 38: 2.659663 learning rate: 10.000000\n",
      "Minibatch perplexity: 14.29\n",
      "================================================================================\n",
      "Validation set perplexity: 12.88\n",
      "Average loss at step 39: 2.591866 learning rate: 10.000000\n",
      "Minibatch perplexity: 13.35\n",
      "================================================================================\n",
      "Validation set perplexity: 14.13\n",
      "Average loss at step 40: 2.756433 learning rate: 10.000000\n",
      "Minibatch perplexity: 15.74\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set perplexity: 16.21\n",
      "Average loss at step 41: 2.804663 learning rate: 10.000000\n",
      "Minibatch perplexity: 16.52\n",
      "================================================================================\n",
      "Validation set perplexity: 13.43\n",
      "Average loss at step 42: 2.685009 learning rate: 10.000000\n",
      "Minibatch perplexity: 14.66\n",
      "================================================================================\n",
      "Validation set perplexity: 13.09\n",
      "Average loss at step 43: 2.616003 learning rate: 10.000000\n",
      "Minibatch perplexity: 13.68\n",
      "================================================================================\n",
      "Validation set perplexity: 12.55\n",
      "Average loss at step 44: 2.534898 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.62\n",
      "================================================================================\n",
      "Validation set perplexity: 12.57\n",
      "Average loss at step 45: 2.584921 learning rate: 10.000000\n",
      "Minibatch perplexity: 13.26\n",
      "================================================================================\n",
      "Validation set perplexity: 12.50\n",
      "Average loss at step 46: 2.502765 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.22\n",
      "================================================================================\n",
      "Validation set perplexity: 12.62\n",
      "Average loss at step 47: 2.580616 learning rate: 10.000000\n",
      "Minibatch perplexity: 13.21\n",
      "================================================================================\n",
      "Validation set perplexity: 12.49\n",
      "Average loss at step 48: 2.528734 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.54\n",
      "================================================================================\n",
      "Validation set perplexity: 12.99\n",
      "Average loss at step 49: 2.652519 learning rate: 10.000000\n",
      "Minibatch perplexity: 14.19\n",
      "================================================================================\n",
      "Validation set perplexity: 12.08\n",
      "Average loss at step 50: 2.550627 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.82\n",
      "================================================================================\n",
      "Validation set perplexity: 12.25\n",
      "Average loss at step 51: 2.587735 learning rate: 10.000000\n",
      "Minibatch perplexity: 13.30\n",
      "================================================================================\n",
      "Validation set perplexity: 11.97\n",
      "Average loss at step 52: 2.513724 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.35\n",
      "================================================================================\n",
      "Validation set perplexity: 11.95\n",
      "Average loss at step 53: 2.569274 learning rate: 10.000000\n",
      "Minibatch perplexity: 13.06\n",
      "================================================================================\n",
      "Validation set perplexity: 11.75\n",
      "Average loss at step 54: 2.535918 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.63\n",
      "================================================================================\n",
      "Validation set perplexity: 12.04\n",
      "Average loss at step 55: 2.517797 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.40\n",
      "================================================================================\n",
      "Validation set perplexity: 12.37\n",
      "Average loss at step 56: 2.550331 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.81\n",
      "================================================================================\n",
      "Validation set perplexity: 12.40\n",
      "Average loss at step 57: 2.587484 learning rate: 10.000000\n",
      "Minibatch perplexity: 13.30\n",
      "================================================================================\n",
      "Validation set perplexity: 12.44\n",
      "Average loss at step 58: 2.496186 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.14\n",
      "================================================================================\n",
      "Validation set perplexity: 11.90\n",
      "Average loss at step 59: 2.471003 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.83\n",
      "================================================================================\n",
      "Validation set perplexity: 12.07\n",
      "Average loss at step 60: 2.499424 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.18\n",
      "================================================================================\n",
      "Validation set perplexity: 11.57\n",
      "Average loss at step 61: 2.491606 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.08\n",
      "================================================================================\n",
      "Validation set perplexity: 11.36\n",
      "Average loss at step 62: 2.496215 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.14\n",
      "================================================================================\n",
      "Validation set perplexity: 11.07\n",
      "Average loss at step 63: 2.468760 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.81\n",
      "================================================================================\n",
      "Validation set perplexity: 11.20\n",
      "Average loss at step 64: 2.458065 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.68\n",
      "================================================================================\n",
      "Validation set perplexity: 10.95\n",
      "Average loss at step 65: 2.478861 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.93\n",
      "================================================================================\n",
      "Validation set perplexity: 11.04\n",
      "Average loss at step 66: 2.406652 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.10\n",
      "================================================================================\n",
      "Validation set perplexity: 10.84\n",
      "Average loss at step 67: 2.416610 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.21\n",
      "================================================================================\n",
      "Validation set perplexity: 11.02\n",
      "Average loss at step 68: 2.384356 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.85\n",
      "================================================================================\n",
      "Validation set perplexity: 10.83\n",
      "Average loss at step 69: 2.451304 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.60\n",
      "================================================================================\n",
      "Validation set perplexity: 12.20\n",
      "Average loss at step 70: 2.466441 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.78\n",
      "================================================================================\n",
      "Validation set perplexity: 13.53\n",
      "Average loss at step 71: 2.694818 learning rate: 10.000000\n",
      "Minibatch perplexity: 14.80\n",
      "================================================================================\n",
      "Validation set perplexity: 12.25\n",
      "Average loss at step 72: 2.503911 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.23\n",
      "================================================================================\n",
      "Validation set perplexity: 11.54\n",
      "Average loss at step 73: 2.494924 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.12\n",
      "================================================================================\n",
      "Validation set perplexity: 11.11\n",
      "Average loss at step 74: 2.389385 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.91\n",
      "================================================================================\n",
      "Validation set perplexity: 10.87\n",
      "Average loss at step 75: 2.425009 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.30\n",
      "================================================================================\n",
      "Validation set perplexity: 10.84\n",
      "Average loss at step 76: 2.383887 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.85\n",
      "================================================================================\n",
      "Validation set perplexity: 10.99\n",
      "Average loss at step 77: 2.428683 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.34\n",
      "================================================================================\n",
      "Validation set perplexity: 10.86\n",
      "Average loss at step 78: 2.386454 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.87\n",
      "================================================================================\n",
      "Validation set perplexity: 10.98\n",
      "Average loss at step 79: 2.333865 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.32\n",
      "================================================================================\n",
      "Validation set perplexity: 10.71\n",
      "Average loss at step 80: 2.347881 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.46\n",
      "================================================================================\n",
      "Validation set perplexity: 12.01\n",
      "Average loss at step 81: 2.407151 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.10\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set perplexity: 11.91\n",
      "Average loss at step 82: 2.485268 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.00\n",
      "================================================================================\n",
      "Validation set perplexity: 11.54\n",
      "Average loss at step 83: 2.423054 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.28\n",
      "================================================================================\n",
      "Validation set perplexity: 11.65\n",
      "Average loss at step 84: 2.424867 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.30\n",
      "================================================================================\n",
      "Validation set perplexity: 10.97\n",
      "Average loss at step 85: 2.466754 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.78\n",
      "================================================================================\n",
      "Validation set perplexity: 10.81\n",
      "Average loss at step 86: 2.421602 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.26\n",
      "================================================================================\n",
      "Validation set perplexity: 10.57\n",
      "Average loss at step 87: 2.370898 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.71\n",
      "================================================================================\n",
      "Validation set perplexity: 10.54\n",
      "Average loss at step 88: 2.358454 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.57\n",
      "================================================================================\n",
      "Validation set perplexity: 10.81\n",
      "Average loss at step 89: 2.446058 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.54\n",
      "================================================================================\n",
      "Validation set perplexity: 10.50\n",
      "Average loss at step 90: 2.353095 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.52\n",
      "================================================================================\n",
      "Validation set perplexity: 11.34\n",
      "Average loss at step 91: 2.416994 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.21\n",
      "================================================================================\n",
      "Validation set perplexity: 11.08\n",
      "Average loss at step 92: 2.403179 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.06\n",
      "================================================================================\n",
      "Validation set perplexity: 11.27\n",
      "Average loss at step 93: 2.355023 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.54\n",
      "================================================================================\n",
      "Validation set perplexity: 11.78\n",
      "Average loss at step 94: 2.370855 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.71\n",
      "================================================================================\n",
      "Validation set perplexity: 11.33\n",
      "Average loss at step 95: 2.389571 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.91\n",
      "================================================================================\n",
      "Validation set perplexity: 11.38\n",
      "Average loss at step 96: 2.428840 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.35\n",
      "================================================================================\n",
      "Validation set perplexity: 10.78\n",
      "Average loss at step 97: 2.358314 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.57\n",
      "================================================================================\n",
      "Validation set perplexity: 10.82\n",
      "Average loss at step 98: 2.379636 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.80\n",
      "================================================================================\n",
      "Validation set perplexity: 10.74\n",
      "Average loss at step 99: 2.330977 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.29\n",
      "================================================================================\n",
      "Validation set perplexity: 10.44\n",
      "Average loss at step 100: 0.024039 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.07\n",
      "================================================================================\n",
      "Validation set perplexity: 10.43\n",
      "Average loss at step 101: 2.302306 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.00\n",
      "================================================================================\n",
      "Validation set perplexity: 10.35\n",
      "Average loss at step 102: 2.279847 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.78\n",
      "================================================================================\n",
      "Validation set perplexity: 10.48\n",
      "Average loss at step 103: 2.284337 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.82\n",
      "================================================================================\n",
      "Validation set perplexity: 10.32\n",
      "Average loss at step 104: 2.375423 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.76\n",
      "================================================================================\n",
      "Validation set perplexity: 10.33\n",
      "Average loss at step 105: 2.283041 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.81\n",
      "================================================================================\n",
      "Validation set perplexity: 10.51\n",
      "Average loss at step 106: 2.286008 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.84\n",
      "================================================================================\n",
      "Validation set perplexity: 10.51\n",
      "Average loss at step 107: 2.371106 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.71\n",
      "================================================================================\n",
      "Validation set perplexity: 11.06\n",
      "Average loss at step 108: 2.375660 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.76\n",
      "================================================================================\n",
      "Validation set perplexity: 10.23\n",
      "Average loss at step 109: 2.372842 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.73\n",
      "================================================================================\n",
      "Validation set perplexity: 10.44\n",
      "Average loss at step 110: 2.292880 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.90\n",
      "================================================================================\n",
      "Validation set perplexity: 9.96\n",
      "Average loss at step 111: 2.297450 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.95\n",
      "================================================================================\n",
      "Validation set perplexity: 11.54\n",
      "Average loss at step 112: 2.290091 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.88\n",
      "================================================================================\n",
      "Validation set perplexity: 11.77\n",
      "Average loss at step 113: 2.489997 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.06\n",
      "================================================================================\n",
      "Validation set perplexity: 11.16\n",
      "Average loss at step 114: 2.390803 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.92\n",
      "================================================================================\n",
      "Validation set perplexity: 10.53\n",
      "Average loss at step 115: 2.318901 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.16\n",
      "================================================================================\n",
      "Validation set perplexity: 10.70\n",
      "Average loss at step 116: 2.410475 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.14\n",
      "================================================================================\n",
      "Validation set perplexity: 10.42\n",
      "Average loss at step 117: 2.323441 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.21\n",
      "================================================================================\n",
      "Validation set perplexity: 10.19\n",
      "Average loss at step 118: 2.319428 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.17\n",
      "================================================================================\n",
      "Validation set perplexity: 10.19\n",
      "Average loss at step 119: 2.384154 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.85\n",
      "================================================================================\n",
      "Validation set perplexity: 10.43\n",
      "Average loss at step 120: 2.395211 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.97\n",
      "================================================================================\n",
      "Validation set perplexity: 10.10\n",
      "Average loss at step 121: 2.362222 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.61\n",
      "================================================================================\n",
      "Validation set perplexity: 10.34\n",
      "Average loss at step 122: 2.381491 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.82\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set perplexity: 10.29\n",
      "Average loss at step 123: 2.244159 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.43\n",
      "================================================================================\n",
      "Validation set perplexity: 10.64\n",
      "Average loss at step 124: 2.339697 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.38\n",
      "================================================================================\n",
      "Validation set perplexity: 10.32\n",
      "Average loss at step 125: 2.355372 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.54\n",
      "================================================================================\n",
      "Validation set perplexity: 10.76\n",
      "Average loss at step 126: 2.379934 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.80\n",
      "================================================================================\n",
      "Validation set perplexity: 11.58\n",
      "Average loss at step 127: 2.450929 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.60\n",
      "================================================================================\n",
      "Validation set perplexity: 10.12\n",
      "Average loss at step 128: 2.214823 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.16\n",
      "================================================================================\n",
      "Validation set perplexity: 10.00\n",
      "Average loss at step 129: 2.316426 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.14\n",
      "================================================================================\n",
      "Validation set perplexity: 10.47\n",
      "Average loss at step 130: 2.331641 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.29\n",
      "================================================================================\n",
      "Validation set perplexity: 10.23\n",
      "Average loss at step 131: 2.340868 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.39\n",
      "================================================================================\n",
      "Validation set perplexity: 10.61\n",
      "Average loss at step 132: 2.324613 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.22\n",
      "================================================================================\n",
      "Validation set perplexity: 10.22\n",
      "Average loss at step 133: 2.294021 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.91\n",
      "================================================================================\n",
      "Validation set perplexity: 10.44\n",
      "Average loss at step 134: 2.289139 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.87\n",
      "================================================================================\n",
      "Validation set perplexity: 10.17\n",
      "Average loss at step 135: 2.294430 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.92\n",
      "================================================================================\n",
      "Validation set perplexity: 11.16\n",
      "Average loss at step 136: 2.325790 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.23\n",
      "================================================================================\n",
      "Validation set perplexity: 11.04\n",
      "Average loss at step 137: 2.402561 learning rate: 10.000000\n",
      "Minibatch perplexity: 11.05\n",
      "================================================================================\n",
      "Validation set perplexity: 10.67\n",
      "Average loss at step 138: 2.265190 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.63\n",
      "================================================================================\n",
      "Validation set perplexity: 9.88\n",
      "Average loss at step 139: 2.306523 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.04\n",
      "================================================================================\n",
      "Validation set perplexity: 9.96\n",
      "Average loss at step 140: 2.222048 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.23\n",
      "================================================================================\n",
      "Validation set perplexity: 9.75\n",
      "Average loss at step 141: 2.280038 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.78\n",
      "================================================================================\n",
      "Validation set perplexity: 9.79\n",
      "Average loss at step 142: 2.296055 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.93\n",
      "================================================================================\n",
      "Validation set perplexity: 9.57\n",
      "Average loss at step 143: 2.260940 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.59\n",
      "================================================================================\n",
      "Validation set perplexity: 9.80\n",
      "Average loss at step 144: 2.220290 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.21\n",
      "================================================================================\n",
      "Validation set perplexity: 9.66\n",
      "Average loss at step 145: 2.225836 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.26\n",
      "================================================================================\n",
      "Validation set perplexity: 9.76\n",
      "Average loss at step 146: 2.237631 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.37\n",
      "================================================================================\n",
      "Validation set perplexity: 10.34\n",
      "Average loss at step 147: 2.328635 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.26\n",
      "================================================================================\n",
      "Validation set perplexity: 10.26\n",
      "Average loss at step 148: 2.370820 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.71\n",
      "================================================================================\n",
      "Validation set perplexity: 10.18\n",
      "Average loss at step 149: 2.252175 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.51\n",
      "================================================================================\n",
      "Validation set perplexity: 9.88\n",
      "Average loss at step 150: 2.203794 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.06\n",
      "================================================================================\n",
      "Validation set perplexity: 10.03\n",
      "Average loss at step 151: 2.245854 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.45\n",
      "================================================================================\n",
      "Validation set perplexity: 9.91\n",
      "Average loss at step 152: 2.264410 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.63\n",
      "================================================================================\n",
      "Validation set perplexity: 10.13\n",
      "Average loss at step 153: 2.218698 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.20\n",
      "================================================================================\n",
      "Validation set perplexity: 9.68\n",
      "Average loss at step 154: 2.262000 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.60\n",
      "================================================================================\n",
      "Validation set perplexity: 10.05\n",
      "Average loss at step 155: 2.208639 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.10\n",
      "================================================================================\n",
      "Validation set perplexity: 9.88\n",
      "Average loss at step 156: 2.274264 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.72\n",
      "================================================================================\n",
      "Validation set perplexity: 10.12\n",
      "Average loss at step 157: 2.222884 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.23\n",
      "================================================================================\n",
      "Validation set perplexity: 9.85\n",
      "Average loss at step 158: 2.143349 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.53\n",
      "================================================================================\n",
      "Validation set perplexity: 9.77\n",
      "Average loss at step 159: 2.234674 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.34\n",
      "================================================================================\n",
      "Validation set perplexity: 9.52\n",
      "Average loss at step 160: 2.220517 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.21\n",
      "================================================================================\n",
      "Validation set perplexity: 9.89\n",
      "Average loss at step 161: 2.226950 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.27\n",
      "================================================================================\n",
      "Validation set perplexity: 9.40\n",
      "Average loss at step 162: 2.262087 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.60\n",
      "================================================================================\n",
      "Validation set perplexity: 9.66\n",
      "Average loss at step 163: 2.146247 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.55\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set perplexity: 9.50\n",
      "Average loss at step 164: 2.304102 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.02\n",
      "================================================================================\n",
      "Validation set perplexity: 9.60\n",
      "Average loss at step 165: 2.238130 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.38\n",
      "================================================================================\n",
      "Validation set perplexity: 9.11\n",
      "Average loss at step 166: 2.178416 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.83\n",
      "================================================================================\n",
      "Validation set perplexity: 9.57\n",
      "Average loss at step 167: 2.191160 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.95\n",
      "================================================================================\n",
      "Validation set perplexity: 9.41\n",
      "Average loss at step 168: 2.095763 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.13\n",
      "================================================================================\n",
      "Validation set perplexity: 9.74\n",
      "Average loss at step 169: 2.231570 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.31\n",
      "================================================================================\n",
      "Validation set perplexity: 9.64\n",
      "Average loss at step 170: 2.194998 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.98\n",
      "================================================================================\n",
      "Validation set perplexity: 9.36\n",
      "Average loss at step 171: 2.184716 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.89\n",
      "================================================================================\n",
      "Validation set perplexity: 9.37\n",
      "Average loss at step 172: 2.239116 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.39\n",
      "================================================================================\n",
      "Validation set perplexity: 9.39\n",
      "Average loss at step 173: 2.259665 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.58\n",
      "================================================================================\n",
      "Validation set perplexity: 10.01\n",
      "Average loss at step 174: 2.274943 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.73\n",
      "================================================================================\n",
      "Validation set perplexity: 9.38\n",
      "Average loss at step 175: 2.250874 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.50\n",
      "================================================================================\n",
      "Validation set perplexity: 9.17\n",
      "Average loss at step 176: 2.252020 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.51\n",
      "================================================================================\n",
      "Validation set perplexity: 9.95\n",
      "Average loss at step 177: 2.183163 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.87\n",
      "================================================================================\n",
      "Validation set perplexity: 9.85\n",
      "Average loss at step 178: 2.281438 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.79\n",
      "================================================================================\n",
      "Validation set perplexity: 10.32\n",
      "Average loss at step 179: 2.223841 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.24\n",
      "================================================================================\n",
      "Validation set perplexity: 9.69\n",
      "Average loss at step 180: 2.317049 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.15\n",
      "================================================================================\n",
      "Validation set perplexity: 9.83\n",
      "Average loss at step 181: 2.184912 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.89\n",
      "================================================================================\n",
      "Validation set perplexity: 9.62\n",
      "Average loss at step 182: 2.216520 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.18\n",
      "================================================================================\n",
      "Validation set perplexity: 10.13\n",
      "Average loss at step 183: 2.265054 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.63\n",
      "================================================================================\n",
      "Validation set perplexity: 9.40\n",
      "Average loss at step 184: 2.131195 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.42\n",
      "================================================================================\n",
      "Validation set perplexity: 9.39\n",
      "Average loss at step 185: 2.209874 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.11\n",
      "================================================================================\n",
      "Validation set perplexity: 9.33\n",
      "Average loss at step 186: 2.165387 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.72\n",
      "================================================================================\n",
      "Validation set perplexity: 9.49\n",
      "Average loss at step 187: 2.155688 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.63\n",
      "================================================================================\n",
      "Validation set perplexity: 9.58\n",
      "Average loss at step 188: 2.135808 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.46\n",
      "================================================================================\n",
      "Validation set perplexity: 9.35\n",
      "Average loss at step 189: 2.150506 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.59\n",
      "================================================================================\n",
      "Validation set perplexity: 9.38\n",
      "Average loss at step 190: 2.045565 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.73\n",
      "================================================================================\n",
      "Validation set perplexity: 9.41\n",
      "Average loss at step 191: 2.276882 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.75\n",
      "================================================================================\n",
      "Validation set perplexity: 9.39\n",
      "Average loss at step 192: 2.210193 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.12\n",
      "================================================================================\n",
      "Validation set perplexity: 9.61\n",
      "Average loss at step 193: 2.167667 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.74\n",
      "================================================================================\n",
      "Validation set perplexity: 9.39\n",
      "Average loss at step 194: 2.303966 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.01\n",
      "================================================================================\n",
      "Validation set perplexity: 9.47\n",
      "Average loss at step 195: 2.247337 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.46\n",
      "================================================================================\n",
      "Validation set perplexity: 9.11\n",
      "Average loss at step 196: 2.252727 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.51\n",
      "================================================================================\n",
      "Validation set perplexity: 8.94\n",
      "Average loss at step 197: 2.204354 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.06\n",
      "================================================================================\n",
      "Validation set perplexity: 9.03\n",
      "Average loss at step 198: 2.080091 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.01\n",
      "================================================================================\n",
      "Validation set perplexity: 8.76\n",
      "Average loss at step 199: 2.215003 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.16\n",
      "================================================================================\n",
      "Validation set perplexity: 8.76\n",
      "Average loss at step 200: 0.021619 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.69\n",
      "================================================================================\n",
      "Validation set perplexity: 8.78\n",
      "Average loss at step 201: 2.262711 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.61\n",
      "================================================================================\n",
      "Validation set perplexity: 9.42\n",
      "Average loss at step 202: 2.064776 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.88\n",
      "================================================================================\n",
      "Validation set perplexity: 9.13\n",
      "Average loss at step 203: 2.187643 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.91\n",
      "================================================================================\n",
      "Validation set perplexity: 9.21\n",
      "Average loss at step 204: 2.168001 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.74\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set perplexity: 9.22\n",
      "Average loss at step 205: 2.134130 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.45\n",
      "================================================================================\n",
      "Validation set perplexity: 8.93\n",
      "Average loss at step 206: 2.161681 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.69\n",
      "================================================================================\n",
      "Validation set perplexity: 8.75\n",
      "Average loss at step 207: 2.069519 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.92\n",
      "================================================================================\n",
      "Validation set perplexity: 9.05\n",
      "Average loss at step 208: 2.198999 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.02\n",
      "================================================================================\n",
      "Validation set perplexity: 9.05\n",
      "Average loss at step 209: 2.170004 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.76\n",
      "================================================================================\n",
      "Validation set perplexity: 9.61\n",
      "Average loss at step 210: 2.231343 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.31\n",
      "================================================================================\n",
      "Validation set perplexity: 9.28\n",
      "Average loss at step 211: 2.124685 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.37\n",
      "================================================================================\n",
      "Validation set perplexity: 8.98\n",
      "Average loss at step 212: 2.107602 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.23\n",
      "================================================================================\n",
      "Validation set perplexity: 8.66\n",
      "Average loss at step 213: 2.237869 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.37\n",
      "================================================================================\n",
      "Validation set perplexity: 8.75\n",
      "Average loss at step 214: 2.033929 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.64\n",
      "================================================================================\n",
      "Validation set perplexity: 8.74\n",
      "Average loss at step 215: 2.116765 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.30\n",
      "================================================================================\n",
      "Validation set perplexity: 8.69\n",
      "Average loss at step 216: 2.133816 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.45\n",
      "================================================================================\n",
      "Validation set perplexity: 8.76\n",
      "Average loss at step 217: 2.178164 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.83\n",
      "================================================================================\n",
      "Validation set perplexity: 8.81\n",
      "Average loss at step 218: 2.106304 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.22\n",
      "================================================================================\n",
      "Validation set perplexity: 8.68\n",
      "Average loss at step 219: 2.124801 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.37\n",
      "================================================================================\n",
      "Validation set perplexity: 8.64\n",
      "Average loss at step 220: 2.162202 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.69\n",
      "================================================================================\n",
      "Validation set perplexity: 9.03\n",
      "Average loss at step 221: 2.204727 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.07\n",
      "================================================================================\n",
      "Validation set perplexity: 8.57\n",
      "Average loss at step 222: 2.154591 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.62\n",
      "================================================================================\n",
      "Validation set perplexity: 8.84\n",
      "Average loss at step 223: 2.182711 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.87\n",
      "================================================================================\n",
      "Validation set perplexity: 9.01\n",
      "Average loss at step 224: 2.167450 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.74\n",
      "================================================================================\n",
      "Validation set perplexity: 9.28\n",
      "Average loss at step 225: 2.288683 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.86\n",
      "================================================================================\n",
      "Validation set perplexity: 8.73\n",
      "Average loss at step 226: 2.153048 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.61\n",
      "================================================================================\n",
      "Validation set perplexity: 8.89\n",
      "Average loss at step 227: 2.161418 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.68\n",
      "================================================================================\n",
      "Validation set perplexity: 8.89\n",
      "Average loss at step 228: 2.167724 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.74\n",
      "================================================================================\n",
      "Validation set perplexity: 8.80\n",
      "Average loss at step 229: 2.066830 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.90\n",
      "================================================================================\n",
      "Validation set perplexity: 8.57\n",
      "Average loss at step 230: 2.165202 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.72\n",
      "================================================================================\n",
      "Validation set perplexity: 8.46\n",
      "Average loss at step 231: 2.144311 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.54\n",
      "================================================================================\n",
      "Validation set perplexity: 9.05\n",
      "Average loss at step 232: 2.043069 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.71\n",
      "================================================================================\n",
      "Validation set perplexity: 8.84\n",
      "Average loss at step 233: 2.204080 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.06\n",
      "================================================================================\n",
      "Validation set perplexity: 8.45\n",
      "Average loss at step 234: 2.124652 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.37\n",
      "================================================================================\n",
      "Validation set perplexity: 8.50\n",
      "Average loss at step 235: 2.154750 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.63\n",
      "================================================================================\n",
      "Validation set perplexity: 8.46\n",
      "Average loss at step 236: 2.055223 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.81\n",
      "================================================================================\n",
      "Validation set perplexity: 8.68\n",
      "Average loss at step 237: 2.040190 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.69\n",
      "================================================================================\n",
      "Validation set perplexity: 8.56\n",
      "Average loss at step 238: 2.044369 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.72\n",
      "================================================================================\n",
      "Validation set perplexity: 8.68\n",
      "Average loss at step 239: 2.116767 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.30\n",
      "================================================================================\n",
      "Validation set perplexity: 8.49\n",
      "Average loss at step 240: 2.172667 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.78\n",
      "================================================================================\n",
      "Validation set perplexity: 8.91\n",
      "Average loss at step 241: 2.100959 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.17\n",
      "================================================================================\n",
      "Validation set perplexity: 8.29\n",
      "Average loss at step 242: 2.195076 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.98\n",
      "================================================================================\n",
      "Validation set perplexity: 8.51\n",
      "Average loss at step 243: 2.088519 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.07\n",
      "================================================================================\n",
      "Validation set perplexity: 8.45\n",
      "Average loss at step 244: 2.131839 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.43\n",
      "================================================================================\n",
      "Validation set perplexity: 8.45\n",
      "Average loss at step 245: 2.138634 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.49\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set perplexity: 8.59\n",
      "Average loss at step 246: 2.105828 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.21\n",
      "================================================================================\n",
      "Validation set perplexity: 8.80\n",
      "Average loss at step 247: 2.049184 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.76\n",
      "================================================================================\n",
      "Validation set perplexity: 8.50\n",
      "Average loss at step 248: 2.085880 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.05\n",
      "================================================================================\n",
      "Validation set perplexity: 8.40\n",
      "Average loss at step 249: 2.078788 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.99\n",
      "================================================================================\n",
      "Validation set perplexity: 8.28\n",
      "Average loss at step 250: 2.084840 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.04\n",
      "================================================================================\n",
      "Validation set perplexity: 8.74\n",
      "Average loss at step 251: 2.136731 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.47\n",
      "================================================================================\n",
      "Validation set perplexity: 8.34\n",
      "Average loss at step 252: 2.089077 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.08\n",
      "================================================================================\n",
      "Validation set perplexity: 8.46\n",
      "Average loss at step 253: 2.055321 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.81\n",
      "================================================================================\n",
      "Validation set perplexity: 8.42\n",
      "Average loss at step 254: 2.093188 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.11\n",
      "================================================================================\n",
      "Validation set perplexity: 8.36\n",
      "Average loss at step 255: 2.119673 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.33\n",
      "================================================================================\n",
      "Validation set perplexity: 8.64\n",
      "Average loss at step 256: 2.173287 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.79\n",
      "================================================================================\n",
      "Validation set perplexity: 8.46\n",
      "Average loss at step 257: 2.098953 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.16\n",
      "================================================================================\n",
      "Validation set perplexity: 8.53\n",
      "Average loss at step 258: 2.068711 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.91\n",
      "================================================================================\n",
      "Validation set perplexity: 8.45\n",
      "Average loss at step 259: 2.110755 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.25\n",
      "================================================================================\n",
      "Validation set perplexity: 9.09\n",
      "Average loss at step 260: 2.108511 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.24\n",
      "================================================================================\n",
      "Validation set perplexity: 8.57\n",
      "Average loss at step 261: 2.030808 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.62\n",
      "================================================================================\n",
      "Validation set perplexity: 8.60\n",
      "Average loss at step 262: 2.189575 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.93\n",
      "================================================================================\n",
      "Validation set perplexity: 8.45\n",
      "Average loss at step 263: 1.982676 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.26\n",
      "================================================================================\n",
      "Validation set perplexity: 8.74\n",
      "Average loss at step 264: 2.160907 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.68\n",
      "================================================================================\n",
      "Validation set perplexity: 8.64\n",
      "Average loss at step 265: 2.041648 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.70\n",
      "================================================================================\n",
      "Validation set perplexity: 8.59\n",
      "Average loss at step 266: 2.104675 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.20\n",
      "================================================================================\n",
      "Validation set perplexity: 8.28\n",
      "Average loss at step 267: 2.066272 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.90\n",
      "================================================================================\n",
      "Validation set perplexity: 8.28\n",
      "Average loss at step 268: 2.181271 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.86\n",
      "================================================================================\n",
      "Validation set perplexity: 8.66\n",
      "Average loss at step 269: 2.137516 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.48\n",
      "================================================================================\n",
      "Validation set perplexity: 8.56\n",
      "Average loss at step 270: 2.173971 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.79\n",
      "================================================================================\n",
      "Validation set perplexity: 8.11\n",
      "Average loss at step 271: 2.027411 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.59\n",
      "================================================================================\n",
      "Validation set perplexity: 8.54\n",
      "Average loss at step 272: 2.150574 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.59\n",
      "================================================================================\n",
      "Validation set perplexity: 8.39\n",
      "Average loss at step 273: 2.100604 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.17\n",
      "================================================================================\n",
      "Validation set perplexity: 8.23\n",
      "Average loss at step 274: 2.001716 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.40\n",
      "================================================================================\n",
      "Validation set perplexity: 8.10\n",
      "Average loss at step 275: 2.045734 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.73\n",
      "================================================================================\n",
      "Validation set perplexity: 8.33\n",
      "Average loss at step 276: 2.021903 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.55\n",
      "================================================================================\n",
      "Validation set perplexity: 8.28\n",
      "Average loss at step 277: 2.059445 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.84\n",
      "================================================================================\n",
      "Validation set perplexity: 8.18\n",
      "Average loss at step 278: 2.167742 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.74\n",
      "================================================================================\n",
      "Validation set perplexity: 8.58\n",
      "Average loss at step 279: 2.151994 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.60\n",
      "================================================================================\n",
      "Validation set perplexity: 8.31\n",
      "Average loss at step 280: 2.139603 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.50\n",
      "================================================================================\n",
      "Validation set perplexity: 8.16\n",
      "Average loss at step 281: 2.030735 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.62\n",
      "================================================================================\n",
      "Validation set perplexity: 8.09\n",
      "Average loss at step 282: 2.032687 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.63\n",
      "================================================================================\n",
      "Validation set perplexity: 8.44\n",
      "Average loss at step 283: 2.091014 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.09\n",
      "================================================================================\n",
      "Validation set perplexity: 8.14\n",
      "Average loss at step 284: 1.990808 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.32\n",
      "================================================================================\n",
      "Validation set perplexity: 8.25\n",
      "Average loss at step 285: 2.034791 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.65\n",
      "================================================================================\n",
      "Validation set perplexity: 8.22\n",
      "Average loss at step 286: 2.131945 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.43\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set perplexity: 8.49\n",
      "Average loss at step 287: 2.117393 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.31\n",
      "================================================================================\n",
      "Validation set perplexity: 8.26\n",
      "Average loss at step 288: 2.098396 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.15\n",
      "================================================================================\n",
      "Validation set perplexity: 8.49\n",
      "Average loss at step 289: 2.178500 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.83\n",
      "================================================================================\n",
      "Validation set perplexity: 8.31\n",
      "Average loss at step 290: 2.072168 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.94\n",
      "================================================================================\n",
      "Validation set perplexity: 8.26\n",
      "Average loss at step 291: 2.105712 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.21\n",
      "================================================================================\n",
      "Validation set perplexity: 8.09\n",
      "Average loss at step 292: 1.989483 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.31\n",
      "================================================================================\n",
      "Validation set perplexity: 8.25\n",
      "Average loss at step 293: 2.046567 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.74\n",
      "================================================================================\n",
      "Validation set perplexity: 8.13\n",
      "Average loss at step 294: 2.049941 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.77\n",
      "================================================================================\n",
      "Validation set perplexity: 8.12\n",
      "Average loss at step 295: 2.064842 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.88\n",
      "================================================================================\n",
      "Validation set perplexity: 8.13\n",
      "Average loss at step 296: 1.970063 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.17\n",
      "================================================================================\n",
      "Validation set perplexity: 8.02\n",
      "Average loss at step 297: 2.068327 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.91\n",
      "================================================================================\n",
      "Validation set perplexity: 8.09\n",
      "Average loss at step 298: 2.016729 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.51\n",
      "================================================================================\n",
      "Validation set perplexity: 7.88\n",
      "Average loss at step 299: 2.022295 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.56\n",
      "================================================================================\n",
      "Validation set perplexity: 7.96\n",
      "Average loss at step 300: 0.020151 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.50\n",
      "================================================================================\n",
      "Validation set perplexity: 8.15\n",
      "Average loss at step 301: 2.004503 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.42\n",
      "================================================================================\n",
      "Validation set perplexity: 8.00\n",
      "Average loss at step 302: 1.987177 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.29\n",
      "================================================================================\n",
      "Validation set perplexity: 8.16\n",
      "Average loss at step 303: 1.977649 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.23\n",
      "================================================================================\n",
      "Validation set perplexity: 7.88\n",
      "Average loss at step 304: 2.045941 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.74\n",
      "================================================================================\n",
      "Validation set perplexity: 7.90\n",
      "Average loss at step 305: 2.024869 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.58\n",
      "================================================================================\n",
      "Validation set perplexity: 8.08\n",
      "Average loss at step 306: 2.049278 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.76\n",
      "================================================================================\n",
      "Validation set perplexity: 8.22\n",
      "Average loss at step 307: 2.041128 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.70\n",
      "================================================================================\n",
      "Validation set perplexity: 8.03\n",
      "Average loss at step 308: 2.139773 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.50\n",
      "================================================================================\n",
      "Validation set perplexity: 7.95\n",
      "Average loss at step 309: 2.183872 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.88\n",
      "================================================================================\n",
      "Validation set perplexity: 8.04\n",
      "Average loss at step 310: 2.091383 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.10\n",
      "================================================================================\n",
      "Validation set perplexity: 8.27\n",
      "Average loss at step 311: 2.153061 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.61\n",
      "================================================================================\n",
      "Validation set perplexity: 8.72\n",
      "Average loss at step 312: 2.113217 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.27\n",
      "================================================================================\n",
      "Validation set perplexity: 8.45\n",
      "Average loss at step 313: 2.061344 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.86\n",
      "================================================================================\n",
      "Validation set perplexity: 8.16\n",
      "Average loss at step 314: 2.117399 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.31\n",
      "================================================================================\n",
      "Validation set perplexity: 8.05\n",
      "Average loss at step 315: 1.966718 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.15\n",
      "================================================================================\n",
      "Validation set perplexity: 7.90\n",
      "Average loss at step 316: 2.034025 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.64\n",
      "================================================================================\n",
      "Validation set perplexity: 8.06\n",
      "Average loss at step 317: 2.008405 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.45\n",
      "================================================================================\n",
      "Validation set perplexity: 8.04\n",
      "Average loss at step 318: 2.119368 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.33\n",
      "================================================================================\n",
      "Validation set perplexity: 8.31\n",
      "Average loss at step 319: 2.107885 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.23\n",
      "================================================================================\n",
      "Validation set perplexity: 8.40\n",
      "Average loss at step 320: 2.069532 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.92\n",
      "================================================================================\n",
      "Validation set perplexity: 8.00\n",
      "Average loss at step 321: 2.077185 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.98\n",
      "================================================================================\n",
      "Validation set perplexity: 8.29\n",
      "Average loss at step 322: 2.109894 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.25\n",
      "================================================================================\n",
      "Validation set perplexity: 8.26\n",
      "Average loss at step 323: 2.065302 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.89\n",
      "================================================================================\n",
      "Validation set perplexity: 8.26\n",
      "Average loss at step 324: 2.007355 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.44\n",
      "================================================================================\n",
      "Validation set perplexity: 7.90\n",
      "Average loss at step 325: 2.007095 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.44\n",
      "================================================================================\n",
      "Validation set perplexity: 8.01\n",
      "Average loss at step 326: 1.939093 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.95\n",
      "================================================================================\n",
      "Validation set perplexity: 7.81\n",
      "Average loss at step 327: 2.029997 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.61\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set perplexity: 8.03\n",
      "Average loss at step 328: 1.964370 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.13\n",
      "================================================================================\n",
      "Validation set perplexity: 8.04\n",
      "Average loss at step 329: 1.981222 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.25\n",
      "================================================================================\n",
      "Validation set perplexity: 7.96\n",
      "Average loss at step 330: 2.013131 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.49\n",
      "================================================================================\n",
      "Validation set perplexity: 7.93\n",
      "Average loss at step 331: 2.008659 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.45\n",
      "================================================================================\n",
      "Validation set perplexity: 7.91\n",
      "Average loss at step 332: 1.999726 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.39\n",
      "================================================================================\n",
      "Validation set perplexity: 7.92\n",
      "Average loss at step 333: 2.076168 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.97\n",
      "================================================================================\n",
      "Validation set perplexity: 7.77\n",
      "Average loss at step 334: 1.963490 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.12\n",
      "================================================================================\n",
      "Validation set perplexity: 8.60\n",
      "Average loss at step 335: 2.031228 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.62\n",
      "================================================================================\n",
      "Validation set perplexity: 8.86\n",
      "Average loss at step 336: 2.130593 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.42\n",
      "================================================================================\n",
      "Validation set perplexity: 8.48\n",
      "Average loss at step 337: 2.046668 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.74\n",
      "================================================================================\n",
      "Validation set perplexity: 7.83\n",
      "Average loss at step 338: 2.074821 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.96\n",
      "================================================================================\n",
      "Validation set perplexity: 7.98\n",
      "Average loss at step 339: 2.083290 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.03\n",
      "================================================================================\n",
      "Validation set perplexity: 7.91\n",
      "Average loss at step 340: 1.998916 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.38\n",
      "================================================================================\n",
      "Validation set perplexity: 7.80\n",
      "Average loss at step 341: 2.012457 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.48\n",
      "================================================================================\n",
      "Validation set perplexity: 7.83\n",
      "Average loss at step 342: 1.933695 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.92\n",
      "================================================================================\n",
      "Validation set perplexity: 7.92\n",
      "Average loss at step 343: 2.026202 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.59\n",
      "================================================================================\n",
      "Validation set perplexity: 7.86\n",
      "Average loss at step 344: 2.126685 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.39\n",
      "================================================================================\n",
      "Validation set perplexity: 8.10\n",
      "Average loss at step 345: 2.061404 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.86\n",
      "================================================================================\n",
      "Validation set perplexity: 7.89\n",
      "Average loss at step 346: 1.949308 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.02\n",
      "================================================================================\n",
      "Validation set perplexity: 8.05\n",
      "Average loss at step 347: 2.082928 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.03\n",
      "================================================================================\n",
      "Validation set perplexity: 8.05\n",
      "Average loss at step 348: 2.058302 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.83\n",
      "================================================================================\n",
      "Validation set perplexity: 7.89\n",
      "Average loss at step 349: 1.942579 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.98\n",
      "================================================================================\n",
      "Validation set perplexity: 7.98\n",
      "Average loss at step 350: 2.020713 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.54\n",
      "================================================================================\n",
      "Validation set perplexity: 8.08\n",
      "Average loss at step 351: 2.058920 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.84\n",
      "================================================================================\n",
      "Validation set perplexity: 7.82\n",
      "Average loss at step 352: 1.949528 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.03\n",
      "================================================================================\n",
      "Validation set perplexity: 7.93\n",
      "Average loss at step 353: 2.046416 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.74\n",
      "================================================================================\n",
      "Validation set perplexity: 7.72\n",
      "Average loss at step 354: 1.932362 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.91\n",
      "================================================================================\n",
      "Validation set perplexity: 7.88\n",
      "Average loss at step 355: 2.008255 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.45\n",
      "================================================================================\n",
      "Validation set perplexity: 8.01\n",
      "Average loss at step 356: 2.014660 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.50\n",
      "================================================================================\n",
      "Validation set perplexity: 7.82\n",
      "Average loss at step 357: 2.015298 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.50\n",
      "================================================================================\n",
      "Validation set perplexity: 7.90\n",
      "Average loss at step 358: 1.912734 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.77\n",
      "================================================================================\n",
      "Validation set perplexity: 7.56\n",
      "Average loss at step 359: 2.079222 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.00\n",
      "================================================================================\n",
      "Validation set perplexity: 7.83\n",
      "Average loss at step 360: 1.878133 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.54\n",
      "================================================================================\n",
      "Validation set perplexity: 7.71\n",
      "Average loss at step 361: 1.924375 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.85\n",
      "================================================================================\n",
      "Validation set perplexity: 8.08\n",
      "Average loss at step 362: 1.972509 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.19\n",
      "================================================================================\n",
      "Validation set perplexity: 7.82\n",
      "Average loss at step 363: 1.948751 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.02\n",
      "================================================================================\n",
      "Validation set perplexity: 7.80\n",
      "Average loss at step 364: 1.881743 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.56\n",
      "================================================================================\n",
      "Validation set perplexity: 8.02\n",
      "Average loss at step 365: 2.008569 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.45\n",
      "================================================================================\n",
      "Validation set perplexity: 7.78\n",
      "Average loss at step 366: 1.954387 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.06\n",
      "================================================================================\n",
      "Validation set perplexity: 7.72\n",
      "Average loss at step 367: 1.873874 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.51\n",
      "================================================================================\n",
      "Validation set perplexity: 7.70\n",
      "Average loss at step 368: 2.036641 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.66\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set perplexity: 7.75\n",
      "Average loss at step 369: 1.987456 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.30\n",
      "================================================================================\n",
      "Validation set perplexity: 7.87\n",
      "Average loss at step 370: 1.946895 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.01\n",
      "================================================================================\n",
      "Validation set perplexity: 7.82\n",
      "Average loss at step 371: 1.964281 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.13\n",
      "================================================================================\n",
      "Validation set perplexity: 7.76\n",
      "Average loss at step 372: 1.861956 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.44\n",
      "================================================================================\n",
      "Validation set perplexity: 7.95\n",
      "Average loss at step 373: 1.997554 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.37\n",
      "================================================================================\n",
      "Validation set perplexity: 7.76\n",
      "Average loss at step 374: 1.925258 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.86\n",
      "================================================================================\n",
      "Validation set perplexity: 7.58\n",
      "Average loss at step 375: 1.955710 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.07\n",
      "================================================================================\n",
      "Validation set perplexity: 7.88\n",
      "Average loss at step 376: 1.885628 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.59\n",
      "================================================================================\n",
      "Validation set perplexity: 8.02\n",
      "Average loss at step 377: 1.983893 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.27\n",
      "================================================================================\n",
      "Validation set perplexity: 7.70\n",
      "Average loss at step 378: 1.894514 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.65\n",
      "================================================================================\n",
      "Validation set perplexity: 7.78\n",
      "Average loss at step 379: 2.028039 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.60\n",
      "================================================================================\n",
      "Validation set perplexity: 8.21\n",
      "Average loss at step 380: 2.046817 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.74\n",
      "================================================================================\n",
      "Validation set perplexity: 7.67\n",
      "Average loss at step 381: 1.905236 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.72\n",
      "================================================================================\n",
      "Validation set perplexity: 7.84\n",
      "Average loss at step 382: 2.020523 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.54\n",
      "================================================================================\n",
      "Validation set perplexity: 7.69\n",
      "Average loss at step 383: 1.862490 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.44\n",
      "================================================================================\n",
      "Validation set perplexity: 7.65\n",
      "Average loss at step 384: 1.887181 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.60\n",
      "================================================================================\n",
      "Validation set perplexity: 7.87\n",
      "Average loss at step 385: 2.115679 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.30\n",
      "================================================================================\n",
      "Validation set perplexity: 7.71\n",
      "Average loss at step 386: 2.026178 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.59\n",
      "================================================================================\n",
      "Validation set perplexity: 7.84\n",
      "Average loss at step 387: 2.053311 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.79\n",
      "================================================================================\n",
      "Validation set perplexity: 7.86\n",
      "Average loss at step 388: 2.047950 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.75\n",
      "================================================================================\n",
      "Validation set perplexity: 7.86\n",
      "Average loss at step 389: 2.028699 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.60\n",
      "================================================================================\n",
      "Validation set perplexity: 7.60\n",
      "Average loss at step 390: 1.972355 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.19\n",
      "================================================================================\n",
      "Validation set perplexity: 8.02\n",
      "Average loss at step 391: 2.113989 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.28\n",
      "================================================================================\n",
      "Validation set perplexity: 7.70\n",
      "Average loss at step 392: 2.013307 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.49\n",
      "================================================================================\n",
      "Validation set perplexity: 7.66\n",
      "Average loss at step 393: 1.913885 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.78\n",
      "================================================================================\n",
      "Validation set perplexity: 7.54\n",
      "Average loss at step 394: 2.001459 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.40\n",
      "================================================================================\n",
      "Validation set perplexity: 7.54\n",
      "Average loss at step 395: 2.006408 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.44\n",
      "================================================================================\n",
      "Validation set perplexity: 7.86\n",
      "Average loss at step 396: 1.927668 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.87\n",
      "================================================================================\n",
      "Validation set perplexity: 7.61\n",
      "Average loss at step 397: 2.015934 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.51\n",
      "================================================================================\n",
      "Validation set perplexity: 7.51\n",
      "Average loss at step 398: 1.985932 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.29\n",
      "================================================================================\n",
      "Validation set perplexity: 7.71\n",
      "Average loss at step 399: 2.058597 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.83\n",
      "================================================================================\n",
      "Validation set perplexity: 7.45\n",
      "Average loss at step 400: 0.019942 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.35\n",
      "================================================================================\n",
      "Validation set perplexity: 7.86\n",
      "Average loss at step 401: 2.036092 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.66\n",
      "================================================================================\n",
      "Validation set perplexity: 7.54\n",
      "Average loss at step 402: 1.900304 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.69\n",
      "================================================================================\n",
      "Validation set perplexity: 7.76\n",
      "Average loss at step 403: 2.010858 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.47\n",
      "================================================================================\n",
      "Validation set perplexity: 7.59\n",
      "Average loss at step 404: 1.912580 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.77\n",
      "================================================================================\n",
      "Validation set perplexity: 7.72\n",
      "Average loss at step 405: 1.852323 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.37\n",
      "================================================================================\n",
      "Validation set perplexity: 7.70\n",
      "Average loss at step 406: 1.979317 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.24\n",
      "================================================================================\n",
      "Validation set perplexity: 7.64\n",
      "Average loss at step 407: 2.133429 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.44\n",
      "================================================================================\n",
      "Validation set perplexity: 7.51\n",
      "Average loss at step 408: 2.039742 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.69\n",
      "================================================================================\n",
      "Validation set perplexity: 7.36\n",
      "Average loss at step 409: 1.961560 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.11\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set perplexity: 7.33\n",
      "Average loss at step 410: 1.981551 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.25\n",
      "================================================================================\n",
      "Validation set perplexity: 7.41\n",
      "Average loss at step 411: 1.983545 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.27\n",
      "================================================================================\n",
      "Validation set perplexity: 7.42\n",
      "Average loss at step 412: 1.917366 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.80\n",
      "================================================================================\n",
      "Validation set perplexity: 7.43\n",
      "Average loss at step 413: 1.948798 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.02\n",
      "================================================================================\n",
      "Validation set perplexity: 7.45\n",
      "Average loss at step 414: 1.877399 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.54\n",
      "================================================================================\n",
      "Validation set perplexity: 7.33\n",
      "Average loss at step 415: 2.019696 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.54\n",
      "================================================================================\n",
      "Validation set perplexity: 7.52\n",
      "Average loss at step 416: 1.954168 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.06\n",
      "================================================================================\n",
      "Validation set perplexity: 7.44\n",
      "Average loss at step 417: 1.930373 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.89\n",
      "================================================================================\n",
      "Validation set perplexity: 7.44\n",
      "Average loss at step 418: 1.936943 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.94\n",
      "================================================================================\n",
      "Validation set perplexity: 7.42\n",
      "Average loss at step 419: 1.832787 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.25\n",
      "================================================================================\n",
      "Validation set perplexity: 7.55\n",
      "Average loss at step 420: 2.025740 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.58\n",
      "================================================================================\n",
      "Validation set perplexity: 7.54\n",
      "Average loss at step 421: 1.822029 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.18\n",
      "================================================================================\n",
      "Validation set perplexity: 7.43\n",
      "Average loss at step 422: 1.836667 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.28\n",
      "================================================================================\n",
      "Validation set perplexity: 7.47\n",
      "Average loss at step 423: 2.044419 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.72\n",
      "================================================================================\n",
      "Validation set perplexity: 7.50\n",
      "Average loss at step 424: 1.952297 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.04\n",
      "================================================================================\n",
      "Validation set perplexity: 7.35\n",
      "Average loss at step 425: 1.924993 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.86\n",
      "================================================================================\n",
      "Validation set perplexity: 7.54\n",
      "Average loss at step 426: 2.043490 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.72\n",
      "================================================================================\n",
      "Validation set perplexity: 7.63\n",
      "Average loss at step 427: 1.898318 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.67\n",
      "================================================================================\n",
      "Validation set perplexity: 7.38\n",
      "Average loss at step 428: 1.933289 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.91\n",
      "================================================================================\n",
      "Validation set perplexity: 7.46\n",
      "Average loss at step 429: 1.960248 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.10\n",
      "================================================================================\n",
      "Validation set perplexity: 7.43\n",
      "Average loss at step 430: 1.921448 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.83\n",
      "================================================================================\n",
      "Validation set perplexity: 7.48\n",
      "Average loss at step 431: 2.066011 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.89\n",
      "================================================================================\n",
      "Validation set perplexity: 7.40\n",
      "Average loss at step 432: 1.826526 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.21\n",
      "================================================================================\n",
      "Validation set perplexity: 7.48\n",
      "Average loss at step 433: 1.947325 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.01\n",
      "================================================================================\n",
      "Validation set perplexity: 7.39\n",
      "Average loss at step 434: 1.917141 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.80\n",
      "================================================================================\n",
      "Validation set perplexity: 7.30\n",
      "Average loss at step 435: 1.948576 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.02\n",
      "================================================================================\n",
      "Validation set perplexity: 7.38\n",
      "Average loss at step 436: 1.902785 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.70\n",
      "================================================================================\n",
      "Validation set perplexity: 7.73\n",
      "Average loss at step 437: 1.965915 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.14\n",
      "================================================================================\n",
      "Validation set perplexity: 7.75\n",
      "Average loss at step 438: 2.093193 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.11\n",
      "================================================================================\n",
      "Validation set perplexity: 7.69\n",
      "Average loss at step 439: 2.039449 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.69\n",
      "================================================================================\n",
      "Validation set perplexity: 7.53\n",
      "Average loss at step 440: 1.893790 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.64\n",
      "================================================================================\n",
      "Validation set perplexity: 7.42\n",
      "Average loss at step 441: 1.794066 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.01\n",
      "================================================================================\n",
      "Validation set perplexity: 7.39\n",
      "Average loss at step 442: 1.748404 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.75\n",
      "================================================================================\n",
      "Validation set perplexity: 7.28\n",
      "Average loss at step 443: 2.112267 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.27\n",
      "================================================================================\n",
      "Validation set perplexity: 7.21\n",
      "Average loss at step 444: 1.959109 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.09\n",
      "================================================================================\n",
      "Validation set perplexity: 7.43\n",
      "Average loss at step 445: 1.872833 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.51\n",
      "================================================================================\n",
      "Validation set perplexity: 7.27\n",
      "Average loss at step 446: 1.706681 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.51\n",
      "================================================================================\n",
      "Validation set perplexity: 7.20\n",
      "Average loss at step 447: 1.956965 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.08\n",
      "================================================================================\n",
      "Validation set perplexity: 7.26\n",
      "Average loss at step 448: 1.938096 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.95\n",
      "================================================================================\n",
      "Validation set perplexity: 7.32\n",
      "Average loss at step 449: 1.985389 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.28\n",
      "================================================================================\n",
      "Validation set perplexity: 7.17\n",
      "Average loss at step 450: 2.044620 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.73\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set perplexity: 7.15\n",
      "Average loss at step 451: 1.865393 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.46\n",
      "================================================================================\n",
      "Validation set perplexity: 7.26\n",
      "Average loss at step 452: 1.824793 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.20\n",
      "================================================================================\n",
      "Validation set perplexity: 7.27\n",
      "Average loss at step 453: 1.999329 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.38\n",
      "================================================================================\n",
      "Validation set perplexity: 7.27\n",
      "Average loss at step 454: 1.878886 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.55\n",
      "================================================================================\n",
      "Validation set perplexity: 7.40\n",
      "Average loss at step 455: 1.933127 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.91\n",
      "================================================================================\n",
      "Validation set perplexity: 7.38\n",
      "Average loss at step 456: 2.006691 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.44\n",
      "================================================================================\n",
      "Validation set perplexity: 7.26\n",
      "Average loss at step 457: 1.926875 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.87\n",
      "================================================================================\n",
      "Validation set perplexity: 7.61\n",
      "Average loss at step 458: 1.841719 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.31\n",
      "================================================================================\n",
      "Validation set perplexity: 7.40\n",
      "Average loss at step 459: 1.873438 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.51\n",
      "================================================================================\n",
      "Validation set perplexity: 7.37\n",
      "Average loss at step 460: 1.895167 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.65\n",
      "================================================================================\n",
      "Validation set perplexity: 7.43\n",
      "Average loss at step 461: 1.927371 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.87\n",
      "================================================================================\n",
      "Validation set perplexity: 7.48\n",
      "Average loss at step 462: 1.914094 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.78\n",
      "================================================================================\n",
      "Validation set perplexity: 7.47\n",
      "Average loss at step 463: 2.078677 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.99\n",
      "================================================================================\n",
      "Validation set perplexity: 7.35\n",
      "Average loss at step 464: 2.119328 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.33\n",
      "================================================================================\n",
      "Validation set perplexity: 7.20\n",
      "Average loss at step 465: 1.879102 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.55\n",
      "================================================================================\n",
      "Validation set perplexity: 7.73\n",
      "Average loss at step 466: 1.957578 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.08\n",
      "================================================================================\n",
      "Validation set perplexity: 7.31\n",
      "Average loss at step 467: 1.915368 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.79\n",
      "================================================================================\n",
      "Validation set perplexity: 7.33\n",
      "Average loss at step 468: 1.994459 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.35\n",
      "================================================================================\n",
      "Validation set perplexity: 7.21\n",
      "Average loss at step 469: 1.894349 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.65\n",
      "================================================================================\n",
      "Validation set perplexity: 7.16\n",
      "Average loss at step 470: 1.848981 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.35\n",
      "================================================================================\n",
      "Validation set perplexity: 7.16\n",
      "Average loss at step 471: 2.031430 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.62\n",
      "================================================================================\n",
      "Validation set perplexity: 7.11\n",
      "Average loss at step 472: 2.000126 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.39\n",
      "================================================================================\n",
      "Validation set perplexity: 7.17\n",
      "Average loss at step 473: 1.896971 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.67\n",
      "================================================================================\n",
      "Validation set perplexity: 7.11\n",
      "Average loss at step 474: 1.845673 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.33\n",
      "================================================================================\n",
      "Validation set perplexity: 7.21\n",
      "Average loss at step 475: 1.928747 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.88\n",
      "================================================================================\n",
      "Validation set perplexity: 7.29\n",
      "Average loss at step 476: 1.939065 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.95\n",
      "================================================================================\n",
      "Validation set perplexity: 7.35\n",
      "Average loss at step 477: 1.946083 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.00\n",
      "================================================================================\n",
      "Validation set perplexity: 7.17\n",
      "Average loss at step 478: 1.907168 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.73\n",
      "================================================================================\n",
      "Validation set perplexity: 7.13\n",
      "Average loss at step 479: 1.882019 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.57\n",
      "================================================================================\n",
      "Validation set perplexity: 7.13\n",
      "Average loss at step 480: 2.018745 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.53\n",
      "================================================================================\n",
      "Validation set perplexity: 7.18\n",
      "Average loss at step 481: 2.044091 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.72\n",
      "================================================================================\n",
      "Validation set perplexity: 7.11\n",
      "Average loss at step 482: 1.924907 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.85\n",
      "================================================================================\n",
      "Validation set perplexity: 7.13\n",
      "Average loss at step 483: 1.935398 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.93\n",
      "================================================================================\n",
      "Validation set perplexity: 7.15\n",
      "Average loss at step 484: 1.974100 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.20\n",
      "================================================================================\n",
      "Validation set perplexity: 7.32\n",
      "Average loss at step 485: 1.955346 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.07\n",
      "================================================================================\n",
      "Validation set perplexity: 7.07\n",
      "Average loss at step 486: 1.998656 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.38\n",
      "================================================================================\n",
      "Validation set perplexity: 6.99\n",
      "Average loss at step 487: 1.968339 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.16\n",
      "================================================================================\n",
      "Validation set perplexity: 7.08\n",
      "Average loss at step 488: 1.944964 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.99\n",
      "================================================================================\n",
      "Validation set perplexity: 7.27\n",
      "Average loss at step 489: 1.925790 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.86\n",
      "================================================================================\n",
      "Validation set perplexity: 7.06\n",
      "Average loss at step 490: 1.917057 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.80\n",
      "================================================================================\n",
      "Validation set perplexity: 7.00\n",
      "Average loss at step 491: 1.893810 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.64\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set perplexity: 7.11\n",
      "Average loss at step 492: 1.873449 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.51\n",
      "================================================================================\n",
      "Validation set perplexity: 7.11\n",
      "Average loss at step 493: 1.948605 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.02\n",
      "================================================================================\n",
      "Validation set perplexity: 7.28\n",
      "Average loss at step 494: 1.943545 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.98\n",
      "================================================================================\n",
      "Validation set perplexity: 7.43\n",
      "Average loss at step 495: 2.096482 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.14\n",
      "================================================================================\n",
      "Validation set perplexity: 7.05\n",
      "Average loss at step 496: 1.950036 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.03\n",
      "================================================================================\n",
      "Validation set perplexity: 7.08\n",
      "Average loss at step 497: 2.005867 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.43\n",
      "================================================================================\n",
      "Validation set perplexity: 6.90\n",
      "Average loss at step 498: 1.964612 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.13\n",
      "================================================================================\n",
      "Validation set perplexity: 6.94\n",
      "Average loss at step 499: 1.857568 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.41\n",
      "================================================================================\n",
      "Validation set perplexity: 7.12\n",
      "Average loss at step 500: 0.018639 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.45\n",
      "================================================================================\n",
      "Validation set perplexity: 7.02\n",
      "Average loss at step 501: 1.843225 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.32\n",
      "================================================================================\n",
      "Validation set perplexity: 7.01\n",
      "Average loss at step 502: 1.852547 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.38\n",
      "================================================================================\n",
      "Validation set perplexity: 6.80\n",
      "Average loss at step 503: 1.908018 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.74\n",
      "================================================================================\n",
      "Validation set perplexity: 7.08\n",
      "Average loss at step 504: 1.919006 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.81\n",
      "================================================================================\n",
      "Validation set perplexity: 7.08\n",
      "Average loss at step 505: 1.911231 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.76\n",
      "================================================================================\n",
      "Validation set perplexity: 7.14\n",
      "Average loss at step 506: 2.000281 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.39\n",
      "================================================================================\n",
      "Validation set perplexity: 6.96\n",
      "Average loss at step 507: 1.884052 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.58\n",
      "================================================================================\n",
      "Validation set perplexity: 7.06\n",
      "Average loss at step 508: 1.813692 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.13\n",
      "================================================================================\n",
      "Validation set perplexity: 7.00\n",
      "Average loss at step 509: 1.778172 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.92\n",
      "================================================================================\n",
      "Validation set perplexity: 6.98\n",
      "Average loss at step 510: 1.964045 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.13\n",
      "================================================================================\n",
      "Validation set perplexity: 7.02\n",
      "Average loss at step 511: 1.881866 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.57\n",
      "================================================================================\n",
      "Validation set perplexity: 6.92\n",
      "Average loss at step 512: 1.915244 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.79\n",
      "================================================================================\n",
      "Validation set perplexity: 7.00\n",
      "Average loss at step 513: 1.927188 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.87\n",
      "================================================================================\n",
      "Validation set perplexity: 7.06\n",
      "Average loss at step 514: 1.944264 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.99\n",
      "================================================================================\n",
      "Validation set perplexity: 7.17\n",
      "Average loss at step 515: 1.835469 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.27\n",
      "================================================================================\n",
      "Validation set perplexity: 6.85\n",
      "Average loss at step 516: 1.990159 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.32\n",
      "================================================================================\n",
      "Validation set perplexity: 6.82\n",
      "Average loss at step 517: 2.001310 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.40\n",
      "================================================================================\n",
      "Validation set perplexity: 6.96\n",
      "Average loss at step 518: 1.888819 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.61\n",
      "================================================================================\n",
      "Validation set perplexity: 6.98\n",
      "Average loss at step 519: 2.059788 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.84\n",
      "================================================================================\n",
      "Validation set perplexity: 6.94\n",
      "Average loss at step 520: 1.946384 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.00\n",
      "================================================================================\n",
      "Validation set perplexity: 6.93\n",
      "Average loss at step 521: 1.986646 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.29\n",
      "================================================================================\n",
      "Validation set perplexity: 7.07\n",
      "Average loss at step 522: 1.851640 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.37\n",
      "================================================================================\n",
      "Validation set perplexity: 6.89\n",
      "Average loss at step 523: 1.954322 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.06\n",
      "================================================================================\n",
      "Validation set perplexity: 7.03\n",
      "Average loss at step 524: 2.031652 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.63\n",
      "================================================================================\n",
      "Validation set perplexity: 7.06\n",
      "Average loss at step 525: 1.891734 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.63\n",
      "================================================================================\n",
      "Validation set perplexity: 7.07\n",
      "Average loss at step 526: 1.971060 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.18\n",
      "================================================================================\n",
      "Validation set perplexity: 6.98\n",
      "Average loss at step 527: 2.031744 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.63\n",
      "================================================================================\n",
      "Validation set perplexity: 7.08\n",
      "Average loss at step 528: 1.995847 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.36\n",
      "================================================================================\n",
      "Validation set perplexity: 6.78\n",
      "Average loss at step 529: 1.892353 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.63\n",
      "================================================================================\n",
      "Validation set perplexity: 6.76\n",
      "Average loss at step 530: 2.016566 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.51\n",
      "================================================================================\n",
      "Validation set perplexity: 6.88\n",
      "Average loss at step 531: 1.900029 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.69\n",
      "================================================================================\n",
      "Validation set perplexity: 6.93\n",
      "Average loss at step 532: 1.926802 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.87\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set perplexity: 7.05\n",
      "Average loss at step 533: 1.893069 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.64\n",
      "================================================================================\n",
      "Validation set perplexity: 6.95\n",
      "Average loss at step 534: 1.919201 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.82\n",
      "================================================================================\n",
      "Validation set perplexity: 6.99\n",
      "Average loss at step 535: 1.784074 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.95\n",
      "================================================================================\n",
      "Validation set perplexity: 6.79\n",
      "Average loss at step 536: 1.864253 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.45\n",
      "================================================================================\n",
      "Validation set perplexity: 6.84\n",
      "Average loss at step 537: 1.937481 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.94\n",
      "================================================================================\n",
      "Validation set perplexity: 6.92\n",
      "Average loss at step 538: 2.000109 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.39\n",
      "================================================================================\n",
      "Validation set perplexity: 7.00\n",
      "Average loss at step 539: 1.941920 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.97\n",
      "================================================================================\n",
      "Validation set perplexity: 6.84\n",
      "Average loss at step 540: 1.931590 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.90\n",
      "================================================================================\n",
      "Validation set perplexity: 7.01\n",
      "Average loss at step 541: 1.902198 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.70\n",
      "================================================================================\n",
      "Validation set perplexity: 6.89\n",
      "Average loss at step 542: 1.866987 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.47\n",
      "================================================================================\n",
      "Validation set perplexity: 7.16\n",
      "Average loss at step 543: 1.902705 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.70\n",
      "================================================================================\n",
      "Validation set perplexity: 7.06\n",
      "Average loss at step 544: 2.047789 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.75\n",
      "================================================================================\n",
      "Validation set perplexity: 7.12\n",
      "Average loss at step 545: 2.020435 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.54\n",
      "================================================================================\n",
      "Validation set perplexity: 7.02\n",
      "Average loss at step 546: 1.828806 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.23\n",
      "================================================================================\n",
      "Validation set perplexity: 6.98\n",
      "Average loss at step 547: 1.971893 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.18\n",
      "================================================================================\n",
      "Validation set perplexity: 6.93\n",
      "Average loss at step 548: 1.856151 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.40\n",
      "================================================================================\n",
      "Validation set perplexity: 7.04\n",
      "Average loss at step 549: 1.889803 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.62\n",
      "================================================================================\n",
      "Validation set perplexity: 7.12\n",
      "Average loss at step 550: 1.825088 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.20\n",
      "================================================================================\n",
      "Validation set perplexity: 7.12\n",
      "Average loss at step 551: 1.933466 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.91\n",
      "================================================================================\n",
      "Validation set perplexity: 6.96\n",
      "Average loss at step 552: 1.938866 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.95\n",
      "================================================================================\n",
      "Validation set perplexity: 6.90\n",
      "Average loss at step 553: 1.989306 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.31\n",
      "================================================================================\n",
      "Validation set perplexity: 6.89\n",
      "Average loss at step 554: 1.904958 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.72\n",
      "================================================================================\n",
      "Validation set perplexity: 6.86\n",
      "Average loss at step 555: 1.990628 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.32\n",
      "================================================================================\n",
      "Validation set perplexity: 7.12\n",
      "Average loss at step 556: 1.899649 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.68\n",
      "================================================================================\n",
      "Validation set perplexity: 6.85\n",
      "Average loss at step 557: 1.742278 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.71\n",
      "================================================================================\n",
      "Validation set perplexity: 6.94\n",
      "Average loss at step 558: 1.841354 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.31\n",
      "================================================================================\n",
      "Validation set perplexity: 6.91\n",
      "Average loss at step 559: 1.905970 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.73\n",
      "================================================================================\n",
      "Validation set perplexity: 6.96\n",
      "Average loss at step 560: 2.036490 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.66\n",
      "================================================================================\n",
      "Validation set perplexity: 6.96\n",
      "Average loss at step 561: 1.977623 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.23\n",
      "================================================================================\n",
      "Validation set perplexity: 6.90\n",
      "Average loss at step 562: 1.902864 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.71\n",
      "================================================================================\n",
      "Validation set perplexity: 6.90\n",
      "Average loss at step 563: 2.005117 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.43\n",
      "================================================================================\n",
      "Validation set perplexity: 7.07\n",
      "Average loss at step 564: 1.877984 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.54\n",
      "================================================================================\n",
      "Validation set perplexity: 6.97\n",
      "Average loss at step 565: 1.848330 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.35\n",
      "================================================================================\n",
      "Validation set perplexity: 6.89\n",
      "Average loss at step 566: 1.874463 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.52\n",
      "================================================================================\n",
      "Validation set perplexity: 7.00\n",
      "Average loss at step 567: 1.829336 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.23\n",
      "================================================================================\n",
      "Validation set perplexity: 6.77\n",
      "Average loss at step 568: 1.984570 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.28\n",
      "================================================================================\n",
      "Validation set perplexity: 7.12\n",
      "Average loss at step 569: 2.063292 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.87\n",
      "================================================================================\n",
      "Validation set perplexity: 6.97\n",
      "Average loss at step 570: 1.931990 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.90\n",
      "================================================================================\n",
      "Validation set perplexity: 6.98\n",
      "Average loss at step 571: 1.913045 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.77\n",
      "================================================================================\n",
      "Validation set perplexity: 6.85\n",
      "Average loss at step 572: 1.880865 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.56\n",
      "================================================================================\n",
      "Validation set perplexity: 6.81\n",
      "Average loss at step 573: 1.939824 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.96\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set perplexity: 6.69\n",
      "Average loss at step 574: 1.859449 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.42\n",
      "================================================================================\n",
      "Validation set perplexity: 6.84\n",
      "Average loss at step 575: 1.936075 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.93\n",
      "================================================================================\n",
      "Validation set perplexity: 6.74\n",
      "Average loss at step 576: 1.844415 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.32\n",
      "================================================================================\n",
      "Validation set perplexity: 6.98\n",
      "Average loss at step 577: 1.726104 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.62\n",
      "================================================================================\n",
      "Validation set perplexity: 6.77\n",
      "Average loss at step 578: 1.822088 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.18\n",
      "================================================================================\n",
      "Validation set perplexity: 6.70\n",
      "Average loss at step 579: 1.783309 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.95\n",
      "================================================================================\n",
      "Validation set perplexity: 6.82\n",
      "Average loss at step 580: 1.898154 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.67\n",
      "================================================================================\n",
      "Validation set perplexity: 6.83\n",
      "Average loss at step 581: 1.912664 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.77\n",
      "================================================================================\n",
      "Validation set perplexity: 6.80\n",
      "Average loss at step 582: 1.889738 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.62\n",
      "================================================================================\n",
      "Validation set perplexity: 6.82\n",
      "Average loss at step 583: 1.896839 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.66\n",
      "================================================================================\n",
      "Validation set perplexity: 7.04\n",
      "Average loss at step 584: 1.992397 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.33\n",
      "================================================================================\n",
      "Validation set perplexity: 7.03\n",
      "Average loss at step 585: 1.833308 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.25\n",
      "================================================================================\n",
      "Validation set perplexity: 6.93\n",
      "Average loss at step 586: 1.832479 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.25\n",
      "================================================================================\n",
      "Validation set perplexity: 6.95\n",
      "Average loss at step 587: 1.805788 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.08\n",
      "================================================================================\n",
      "Validation set perplexity: 7.01\n",
      "Average loss at step 588: 2.037628 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.67\n",
      "================================================================================\n",
      "Validation set perplexity: 6.94\n",
      "Average loss at step 589: 1.980255 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.24\n",
      "================================================================================\n",
      "Validation set perplexity: 6.96\n",
      "Average loss at step 590: 1.817454 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.16\n",
      "================================================================================\n",
      "Validation set perplexity: 6.84\n",
      "Average loss at step 591: 1.889879 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.62\n",
      "================================================================================\n",
      "Validation set perplexity: 6.95\n",
      "Average loss at step 592: 1.831079 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.24\n",
      "================================================================================\n",
      "Validation set perplexity: 6.87\n",
      "Average loss at step 593: 1.935975 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.93\n",
      "================================================================================\n",
      "Validation set perplexity: 7.06\n",
      "Average loss at step 594: 1.906977 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.73\n",
      "================================================================================\n",
      "Validation set perplexity: 6.89\n",
      "Average loss at step 595: 1.946958 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.01\n",
      "================================================================================\n",
      "Validation set perplexity: 6.88\n",
      "Average loss at step 596: 1.836995 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.28\n",
      "================================================================================\n",
      "Validation set perplexity: 7.09\n",
      "Average loss at step 597: 1.948269 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.02\n",
      "================================================================================\n",
      "Validation set perplexity: 6.73\n",
      "Average loss at step 598: 1.696840 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.46\n",
      "================================================================================\n",
      "Validation set perplexity: 6.97\n",
      "Average loss at step 599: 1.782043 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.94\n",
      "================================================================================\n",
      "Validation set perplexity: 6.86\n",
      "Average loss at step 600: 0.018279 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.22\n",
      "================================================================================\n",
      "Validation set perplexity: 7.02\n",
      "Average loss at step 601: 1.813105 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.13\n",
      "================================================================================\n",
      "Validation set perplexity: 6.78\n",
      "Average loss at step 602: 1.931315 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.90\n",
      "================================================================================\n",
      "Validation set perplexity: 6.89\n",
      "Average loss at step 603: 1.972790 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.19\n",
      "================================================================================\n",
      "Validation set perplexity: 6.71\n",
      "Average loss at step 604: 1.928598 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.88\n",
      "================================================================================\n",
      "Validation set perplexity: 6.79\n",
      "Average loss at step 605: 1.943070 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.98\n",
      "================================================================================\n",
      "Validation set perplexity: 6.89\n",
      "Average loss at step 606: 1.852360 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.37\n",
      "================================================================================\n",
      "Validation set perplexity: 6.98\n",
      "Average loss at step 607: 1.834064 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.26\n",
      "================================================================================\n",
      "Validation set perplexity: 7.11\n",
      "Average loss at step 608: 1.853800 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.38\n",
      "================================================================================\n",
      "Validation set perplexity: 6.91\n",
      "Average loss at step 609: 1.741525 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.71\n",
      "================================================================================\n",
      "Validation set perplexity: 6.80\n",
      "Average loss at step 610: 1.773929 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.89\n",
      "================================================================================\n",
      "Validation set perplexity: 6.98\n",
      "Average loss at step 611: 1.915208 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.79\n",
      "================================================================================\n",
      "Validation set perplexity: 6.81\n",
      "Average loss at step 612: 1.841123 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.30\n",
      "================================================================================\n",
      "Validation set perplexity: 6.82\n",
      "Average loss at step 613: 1.905664 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.72\n",
      "================================================================================\n",
      "Validation set perplexity: 6.92\n",
      "Average loss at step 614: 1.847872 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.35\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set perplexity: 6.82\n",
      "Average loss at step 615: 1.908174 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.74\n",
      "================================================================================\n",
      "Validation set perplexity: 6.78\n",
      "Average loss at step 616: 1.863564 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.45\n",
      "================================================================================\n",
      "Validation set perplexity: 6.71\n",
      "Average loss at step 617: 1.899704 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.68\n",
      "================================================================================\n",
      "Validation set perplexity: 6.83\n",
      "Average loss at step 618: 1.760037 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.81\n",
      "================================================================================\n",
      "Validation set perplexity: 6.76\n",
      "Average loss at step 619: 1.771219 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.88\n",
      "================================================================================\n",
      "Validation set perplexity: 6.77\n",
      "Average loss at step 620: 1.878053 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.54\n",
      "================================================================================\n",
      "Validation set perplexity: 6.80\n",
      "Average loss at step 621: 1.751083 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.76\n",
      "================================================================================\n",
      "Validation set perplexity: 6.68\n",
      "Average loss at step 622: 1.823550 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.19\n",
      "================================================================================\n",
      "Validation set perplexity: 6.73\n",
      "Average loss at step 623: 1.907761 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.74\n",
      "================================================================================\n",
      "Validation set perplexity: 6.64\n",
      "Average loss at step 624: 1.897354 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.67\n",
      "================================================================================\n",
      "Validation set perplexity: 6.56\n",
      "Average loss at step 625: 1.847819 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.35\n",
      "================================================================================\n",
      "Validation set perplexity: 6.59\n",
      "Average loss at step 626: 1.810469 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.11\n",
      "================================================================================\n",
      "Validation set perplexity: 6.66\n",
      "Average loss at step 627: 1.875095 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.52\n",
      "================================================================================\n",
      "Validation set perplexity: 6.67\n",
      "Average loss at step 628: 1.883048 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.57\n",
      "================================================================================\n",
      "Validation set perplexity: 6.46\n",
      "Average loss at step 629: 1.819852 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.17\n",
      "================================================================================\n",
      "Validation set perplexity: 6.76\n",
      "Average loss at step 630: 1.943900 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.99\n",
      "================================================================================\n",
      "Validation set perplexity: 6.64\n",
      "Average loss at step 631: 1.921442 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.83\n",
      "================================================================================\n",
      "Validation set perplexity: 6.73\n",
      "Average loss at step 632: 1.893391 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.64\n",
      "================================================================================\n",
      "Validation set perplexity: 6.69\n",
      "Average loss at step 633: 1.967091 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.15\n",
      "================================================================================\n",
      "Validation set perplexity: 6.82\n",
      "Average loss at step 634: 1.905223 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.72\n",
      "================================================================================\n",
      "Validation set perplexity: 6.78\n",
      "Average loss at step 635: 1.860334 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.43\n",
      "================================================================================\n",
      "Validation set perplexity: 6.77\n",
      "Average loss at step 636: 1.757406 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.80\n",
      "================================================================================\n",
      "Validation set perplexity: 6.89\n",
      "Average loss at step 637: 1.812603 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.13\n",
      "================================================================================\n",
      "Validation set perplexity: 6.78\n",
      "Average loss at step 638: 1.984820 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.28\n",
      "================================================================================\n",
      "Validation set perplexity: 6.81\n",
      "Average loss at step 639: 1.827276 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.22\n",
      "================================================================================\n",
      "Validation set perplexity: 6.81\n",
      "Average loss at step 640: 2.015085 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.50\n",
      "================================================================================\n",
      "Validation set perplexity: 6.73\n",
      "Average loss at step 641: 1.847633 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.34\n",
      "================================================================================\n",
      "Validation set perplexity: 7.11\n",
      "Average loss at step 642: 1.930773 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.89\n",
      "================================================================================\n",
      "Validation set perplexity: 6.83\n",
      "Average loss at step 643: 1.840293 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.30\n",
      "================================================================================\n",
      "Validation set perplexity: 6.78\n",
      "Average loss at step 644: 1.930639 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.89\n",
      "================================================================================\n",
      "Validation set perplexity: 6.73\n",
      "Average loss at step 645: 1.982908 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.26\n",
      "================================================================================\n",
      "Validation set perplexity: 6.59\n",
      "Average loss at step 646: 1.936121 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.93\n",
      "================================================================================\n",
      "Validation set perplexity: 6.95\n",
      "Average loss at step 647: 1.757221 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.80\n",
      "================================================================================\n",
      "Validation set perplexity: 6.76\n",
      "Average loss at step 648: 1.988527 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.30\n",
      "================================================================================\n",
      "Validation set perplexity: 6.65\n",
      "Average loss at step 649: 1.898841 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.68\n",
      "================================================================================\n",
      "Validation set perplexity: 6.75\n",
      "Average loss at step 650: 1.740510 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.70\n",
      "================================================================================\n",
      "Validation set perplexity: 6.68\n",
      "Average loss at step 651: 1.904993 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.72\n",
      "================================================================================\n",
      "Validation set perplexity: 6.58\n",
      "Average loss at step 652: 1.751056 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.76\n",
      "================================================================================\n",
      "Validation set perplexity: 6.65\n",
      "Average loss at step 653: 1.691233 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.43\n",
      "================================================================================\n",
      "Validation set perplexity: 6.63\n",
      "Average loss at step 654: 1.820384 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.17\n",
      "================================================================================\n",
      "Validation set perplexity: 6.65\n",
      "Average loss at step 655: 1.880129 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.55\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set perplexity: 6.62\n",
      "Average loss at step 656: 1.973154 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.19\n",
      "================================================================================\n",
      "Validation set perplexity: 6.95\n",
      "Average loss at step 657: 1.981657 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.25\n",
      "================================================================================\n",
      "Validation set perplexity: 7.05\n",
      "Average loss at step 658: 1.990287 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.32\n",
      "================================================================================\n",
      "Validation set perplexity: 7.02\n",
      "Average loss at step 659: 1.828815 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.23\n",
      "================================================================================\n",
      "Validation set perplexity: 6.73\n",
      "Average loss at step 660: 1.916882 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.80\n",
      "================================================================================\n",
      "Validation set perplexity: 7.02\n",
      "Average loss at step 661: 1.856605 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.40\n",
      "================================================================================\n",
      "Validation set perplexity: 6.68\n",
      "Average loss at step 662: 1.881298 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.56\n",
      "================================================================================\n",
      "Validation set perplexity: 6.68\n",
      "Average loss at step 663: 1.891371 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.63\n",
      "================================================================================\n",
      "Validation set perplexity: 6.85\n",
      "Average loss at step 664: 1.883477 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.58\n",
      "================================================================================\n",
      "Validation set perplexity: 6.85\n",
      "Average loss at step 665: 1.760123 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.81\n",
      "================================================================================\n",
      "Validation set perplexity: 6.76\n",
      "Average loss at step 666: 1.904222 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.71\n",
      "================================================================================\n",
      "Validation set perplexity: 6.55\n",
      "Average loss at step 667: 1.772426 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.89\n",
      "================================================================================\n",
      "Validation set perplexity: 6.61\n",
      "Average loss at step 668: 1.858645 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.42\n",
      "================================================================================\n",
      "Validation set perplexity: 6.61\n",
      "Average loss at step 669: 1.797625 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.04\n",
      "================================================================================\n",
      "Validation set perplexity: 6.63\n",
      "Average loss at step 670: 1.763708 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.83\n",
      "================================================================================\n",
      "Validation set perplexity: 6.67\n",
      "Average loss at step 671: 1.873728 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.51\n",
      "================================================================================\n",
      "Validation set perplexity: 6.53\n",
      "Average loss at step 672: 1.783148 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.95\n",
      "================================================================================\n",
      "Validation set perplexity: 6.49\n",
      "Average loss at step 673: 1.944530 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.99\n",
      "================================================================================\n",
      "Validation set perplexity: 6.66\n",
      "Average loss at step 674: 1.853828 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.38\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "num_steps = 7001\n",
    "summary_frequency = 100\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    mean_loss = 0\n",
    "    for step in range(num_steps):\n",
    "        batches = train_batches.next()\n",
    "        feed_dict = dict()\n",
    "        for i in range(num_unrollings + 1):\n",
    "            feed_dict[train_data[i]] = batches[i]\n",
    "        _, l, predictions, lr = session.run([optimizer, loss, train_prediction, learning_rate], feed_dict=feed_dict)\n",
    "        mean_loss += l\n",
    "        if step % summary_frequency == 0:\n",
    "            if step > 0:\n",
    "                mean_loss = mean_loss / summary_frequency\n",
    "        # The mean loss is an estimate of the loss over the last few batches.\n",
    "        print('Average loss at step %d: %f learning rate: %f' % (step, mean_loss, lr))\n",
    "        mean_loss = 0\n",
    "        labels = np.concatenate(list(batches)[1:])\n",
    "        print('Minibatch perplexity: %.2f' % float(\n",
    "            np.exp(logprob(predictions, labels))))\n",
    "        if step % (summary_frequency * 10) == 0:\n",
    "            # Generate some samples.\n",
    "            print('=' * 80)\n",
    "            for _ in range(5):\n",
    "                feed = sample(random_distribution())\n",
    "                sentence = characters(feed)[0]\n",
    "                reset_sample_state.run()\n",
    "                for _ in range(79):\n",
    "                    prediction = sample_prediction.eval({sample_input: feed})\n",
    "                    feed = sample(prediction)\n",
    "                    sentence += characters(feed)[0]\n",
    "            print(sentence)\n",
    "        print('=' * 80)\n",
    "        # Measure validation set perplexity.\n",
    "        reset_sample_state.run()\n",
    "        valid_logprob = 0\n",
    "        for _ in range(valid_size):\n",
    "            b = valid_batches.next()\n",
    "            predictions = sample_prediction.eval({sample_input: b[0]})\n",
    "            valid_logprob = valid_logprob + logprob(predictions, b[1])\n",
    "        print('Validation set perplexity: %.2f' % float(np.exp(\n",
    "            valid_logprob / valid_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pl4vtmFfa5nn"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "You might have noticed that the definition of the LSTM cell involves 4 matrix multiplications with the input, and 4 matrix multiplications with the output. Simplify the expression by using a single matrix multiply for each, and variables that are 4 times larger.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4eErTCTybtph"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "\n",
    "We want to train a LSTM over bigrams, that is pairs of consecutive characters like 'ab' instead of single characters like 'a'. Since the number of possible bigrams is large, feeding them directly to the LSTM using 1-hot encodings will lead to a very sparse representation that is very wasteful computationally.\n",
    "\n",
    "a- Introduce an embedding lookup on the inputs, and feed the embeddings to the LSTM cell instead of the inputs themselves.\n",
    "\n",
    "b- Write a bigram-based LSTM, modeled on the character LSTM above.\n",
    "\n",
    "c- Introduce Dropout. For best practices on how to use Dropout in LSTMs, refer to this [article](http://arxiv.org/abs/1409.2329).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5tapX3kpcqZ"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "\n",
    "(difficult!)\n",
    "\n",
    "Write a sequence-to-sequence LSTM which mirrors all the words in a sentence. For example, if your input is:\n",
    "\n",
    "    the quick brown fox\n",
    "    \n",
    "the model should attempt to output:\n",
    "\n",
    "    eht kciuq nworb xof\n",
    "    \n",
    "Refer to the lecture on how to put together a sequence-to-sequence model, as well as [this article](http://arxiv.org/abs/1409.3215) for best practices.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "6_lstm.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
